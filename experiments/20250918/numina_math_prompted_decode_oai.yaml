experiment:
  table_name: encoding_schemes

  project_name: encoding_schemes
  experiment_name: mathcot_prompteddecode_${encoding_scheme}_${model_id}

  experiment_params:
    model: ${model_id}
    encoding_scheme: ${encoding_scheme}

    dataset: numina_math_cot_16000
    validation_set_frac: 0.05

    sampling_params:
      temperature: 1.0
      n: 1

    base_url: https://api.openai.com/v1/

    translation_prompt: ${encoding_scheme}
    
  experiment_tags:
    numina_math_cot_rerun: True

stages:

  - name: generate_ground_truth_translation_math500_cot
    executor:
      path: speaking/encoded_cot_runner.py
      function_name: generate_ground_truth_translation
      function_kwargs:
        dataset_override: prm800k_test_raw
        validation_set_frac_override: 0.0

  - name: generate_math500_reverse_translation
    executor:
      path: translation/run_reverse_translation.py
      function_name: generate_openai_prompted_translation
      function_kwargs:
        skip_too_long: False
        reference_text_col: raw_translated_cot
        translated_text_col: reference_solution
        translation_prompt_override: reverse_translation_general_decoding_cot
        prompt_prefix_override: ""
        translation_extraction_tag: translation

    force_overwrite: True

  - name: evaluate_bleu_score
    executor:
      path: evaluation/metrics/translation.py
      function_name: evaluate_bleu_score
      function_kwargs: {}

    force_overwrite: True

  - name: combine_all_result_dfs
    executor:
      path: utils/io_utils.py
      function_name: combine_translation_math_cot_dfs
      function_kwargs:
        fake_prompted_cot_math_dfs: True

    force_overwrite: True
