experiment:
  table_name: encoding_schemes

  project_name: encoding_schemes
  experiment_name: math_cot_sft_${encoding_scheme}_${model_id}

  experiment_params:
    model: ${model_id}
    encoding_scheme: ${encoding_scheme}

    dataset: numina_math_cot_64000
    validation_set_frac: 0.2

    sampling_params:
      temperature: 1.0
      n: 1

    sft_params:
      batch_size: 128
      learning_rate: 2e-6
      clip_grad: 1.0
      num_epochs: 1
      weight_decay: 0.0

    translation_prompt: ${encoding_scheme}
    
    use_sft_model_for_sampling: True

  experiment_tags:

stages:
  - name: generate_ground_truth_translation
    executor:
      path: speaking/encoded_cot_runner.py
      function_name: generate_ground_truth_translation
      function_kwargs: {}

  - name: generate_sft_dataset
    executor:
      path: speaking/encoded_cot_runner.py
      function_name: generate_sft_dataset
      function_kwargs: {}

  - name: sft_model
    executor:
      path: sft/sft_runner.py
      function_name: sft_model
      function_kwargs: {}

  - name: generate_prompted_translation
    executor:
      path: speaking/encoded_cot_runner.py
      function_name: generate_prompted_translation
      function_kwargs: {}

  - name: judge_cot_encoding_English_coherence
    executor:
      path: speaking/encoded_cot_runner.py
      function_name: judge_cot_encoding_English_coherence
      function_kwargs: {}

  - name: judge_cot_style_adherence
    executor:
      path: speaking/encoded_cot_runner.py
      function_name: judge_cot_style_adherence
      function_kwargs: {}

  - name: evaluate_math_accuracy
    executor:
      path: evaluation/metrics/math_accuracy.py
      function_name: evaluate_math_accuracy
      function_kwargs: {}