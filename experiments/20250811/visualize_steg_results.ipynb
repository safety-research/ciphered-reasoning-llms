{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d0a44-0aae-4a22-9ea2-552f1efd9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8432f-7bb7-4bb8-8223-ea329456a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8ad9e-91d3-4e3b-b25c-9f19f3e4b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "conn_string = os.environ[\"SUPABASE_CONNECTION_URL\"]\n",
    "\n",
    "conn = psycopg2.connect(conn_string)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b3a2c-ade1-42ca-a798-5b94232485d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql(\"SELECT * FROM public.encoding_schemes WHERE (data->'experiment_tags'->'sft')::boolean\", conn)\n",
    "df = pd.read_sql(\"\"\"\n",
    "SELECT * FROM public.encoding_schemes \n",
    "    WHERE \n",
    "\n",
    "    (\n",
    "        (data->'experiment_params'->'encoding_scheme')::TEXT LIKE '%speaking_math_%_steg%'\n",
    "        OR (data->'experiment_params'->'encoding_scheme')::TEXT LIKE '%identity%'\n",
    "        OR (data->'experiment_params'->'encoding_scheme')::TEXT LIKE '%zero_shot%'\n",
    "    )\n",
    "    AND (data->'experiment_params'->'use_sft_model_for_sampling')::BOOL\n",
    "    AND (data->'experiment_params'->'model')::TEXT LIKE '%Qwen2.5%'\n",
    "    AND (data->'experiment_params'->'model')::TEXT NOT LIKE '%32B%'\n",
    "    AND (data->'experiment_params'->'sampling_params'->'n')::INT = 1\n",
    "\n",
    "ORDER BY created_at DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e2fc7e-abc9-4559-b5bd-a8b11c34461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439f59a-7755-482d-ac55-c324ac5bed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"~/sky_workdir/encoding-schemes/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d72f27-7ec8-4ffd-b530-f2b0b27cefab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_examples = df.to_dict('records')\n",
    "\n",
    "l_examples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a81ec-f561-430e-8570-c9d4a2a0f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap_ci(data, statistic=np.mean, alpha=0.05, n_boot=10_000, random_state=None):\n",
    "    \"\"\"\n",
    "    Returns (point_estimate, low_CI, high_CI) for given 1D data.\n",
    "    Works with bool, int, or float data.\n",
    "    \"\"\"\n",
    "    x = np.asarray(data).astype(float)  # ensure numeric\n",
    "    x = x[~np.isnan(x)]\n",
    "    if len(x) == 0:\n",
    "        raise ValueError(\"No valid data for bootstrapping.\")\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(x)\n",
    "\n",
    "    # Draw bootstrap samples\n",
    "    idx = rng.integers(0, n, size=(n_boot, n))\n",
    "    samples = x[idx]\n",
    "\n",
    "    # Apply statistic row-wise\n",
    "    stats = np.apply_along_axis(statistic, 1, samples)\n",
    "\n",
    "    point = statistic(x)\n",
    "    lo = np.percentile(stats, 100 * (alpha / 2))\n",
    "    hi = np.percentile(stats, 100 * (1 - alpha / 2))\n",
    "    return point, lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fb9f9-33d1-4e61-b837-cc8b37219291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def count_tokens_from_messages(s):\n",
    "    try:\n",
    "        return len(encoding.encode(s, disallowed_special=()))\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f84e71-0f86-4e06-b744-96e3e6a71ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73907c00-ce16-4bce-b6e9-14d9bb68e0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for example in l_examples:\n",
    "    try:\n",
    "        df_data = pd.read_parquet(os.path.join(root_dir, example['experiment_hash'], \"data\", \"math_scores.parquet\"))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    df_sft_data = pd.read_parquet(os.path.join(root_dir, example['experiment_hash'], \"data\", \"sft.parquet\"))\n",
    "    df_prompted_cot = pd.read_parquet(os.path.join(root_dir, example['experiment_hash'], \"data\", \"prompted_cot.parquet\"))\n",
    "\n",
    "    try:\n",
    "        example['contains_math_solving'] = df_prompted_cot['contains_math_solving'].apply(np.mean).mean()\n",
    "        mid, lo, hi = bootstrap_ci(df_prompted_cot['contains_math_solving'].apply(np.mean))\n",
    "        example['contains_math_solving_low_ci'] = mid - lo\n",
    "        example['contains_math_solving_hi_ci'] = hi - mid\n",
    "    except Exception as e:\n",
    "        print(e, example['data'])\n",
    "    \n",
    "    example['is_corrects'] = df_data['is_corrects'].apply(np.mean).mean()\n",
    "    mid, lo, hi = bootstrap_ci(df_data['is_corrects'].apply(np.mean))\n",
    "    example['is_corrects_low_ci'] = mid - lo\n",
    "    example['is_corrects_hi_ci'] = hi - mid\n",
    "\n",
    "    example['followed_encoding_style_raw'] = df_prompted_cot['followed_encoding_style']\n",
    "    example['followed_encoding_style'] = df_prompted_cot['followed_encoding_style'].apply(np.mean).mean()\n",
    "    mid, lo, hi = bootstrap_ci(df_prompted_cot['followed_encoding_style'].apply(np.mean))\n",
    "    example['followed_encoding_style_low_ci'] = mid - lo\n",
    "    example['followed_encoding_style_hi_ci'] = hi - mid\n",
    "    \n",
    "    example['reference_translation'] = df_sft_data['messages'].map(lambda x: x[-1]['content'])\n",
    "\n",
    "    # l_token_lens = []\n",
    "    # for decoded_cot in tqdm(df_data['decoded_cot']):\n",
    "    #     l_token_lens.extend([count_tokens_from_messages.remote(s) for s in decoded_cot])\n",
    "    # l_token_lens = ray.get(l_token_lens)\n",
    "\n",
    "    # example['num_tokens_output'] = l_token_lens\n",
    "\n",
    "    for col in df_data.columns:\n",
    "        example[f\"{col}_df\"] = df_data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ff331-89cd-4e85-88c4-b272cbaad110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example in l_examples:\n",
    "#     df_sft_train = pd.read_parquet(os.path.join(root_dir, example['experiment_hash'], \"data\", \"sft_train.parquet\"))\n",
    "\n",
    "#     l_token_lens = []\n",
    "#     for conversation in tqdm(df_sft_train['messages']):\n",
    "#         l_token_lens.extend([count_tokens_from_messages.remote(s[\"content\"]) for s in conversation])\n",
    "#     l_token_lens = ray.get(l_token_lens)\n",
    "\n",
    "#     example[\"n_total_train_tok\"] = np.sum(l_token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535167c-564e-4e1a-80c1-323f1a8eb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7b0cc-4d72-4780-9f3a-0fa25ee3a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize_number(num: float) -> str:\n",
    "    \"\"\"\n",
    "    Converts a number into a human-readable string with k, M, or B suffixes.\n",
    "    \n",
    "    Args:\n",
    "        num (float): The number to format.\n",
    "    \n",
    "    Returns:\n",
    "        str: Human-readable string representation.\n",
    "    \"\"\"\n",
    "    if num >= 1_000_000_000:\n",
    "        return f\"{num / 1_000_000_000:.1f}B\"\n",
    "    elif num >= 1_000_000:\n",
    "        return f\"{num / 1_000_000:.1f}M\"\n",
    "    elif num >= 1_000:\n",
    "        return f\"{num / 1_000:.1f}k\"\n",
    "    else:\n",
    "        return str(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c8aa3-b7b1-48a7-b0fc-c8811fe9a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_params(model):\n",
    "    if 'gpt' in model:\n",
    "        if 'nano' in model:\n",
    "            return 0\n",
    "        elif 'mini' in model:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "\n",
    "    if 'claude' in model:\n",
    "        if 'haiku' in model:\n",
    "            return 3\n",
    "        elif 'sonnet' in model:\n",
    "            return 4\n",
    "        else:\n",
    "            return 5\n",
    "    \n",
    "    return int(re.search(\"([0-9]+)B\", model).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6fff7c-63da-4eaa-a7a5-4d15727471c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/sky_workdir/encoding-schemes\")\n",
    "\n",
    "from evaluation.metrics.math_accuracy import extract_answer, timeout\n",
    "from verl.utils.reward_score.math import compute_score, last_boxed_only_string, remove_boxed\n",
    "\n",
    "\n",
    "def calculate_accuracy(example):\n",
    "    df_sft_train = pd.read_parquet(os.path.join(root_dir, example['experiment_hash'], \"data\", \"sft_train.parquet\"))\n",
    "    df_gt = pd.read_parquet(os.path.join(root_dir, example['experiment_hash'], \"data\", \"ground_truth_translation_train.parquet\"))\n",
    "\n",
    "    print(len(df_gt), len(df_sft_train))\n",
    "    if len(df_gt) != len(df_sft_train):\n",
    "        return []\n",
    "    \n",
    "    l_correct = []\n",
    "    for i, row in df_sft_train.iterrows():\n",
    "        l_sample_correct = []\n",
    "\n",
    "        try:\n",
    "            with timeout():\n",
    "                extracted_model_response = extract_answer(row[\"messages\"][-1][\"content\"])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            l_sample_correct.append(0.0)\n",
    "            continue\n",
    "\n",
    "        if len(extracted_model_response) == 0:\n",
    "            l_sample_correct.append(0.0)\n",
    "            continue\n",
    "\n",
    "        if len(df_gt.iloc[i][\"answer\"]) == 0:\n",
    "            l_sample_correct.append(0.0)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with timeout():\n",
    "                l_sample_correct.append(compute_score(extracted_model_response, df_gt.iloc[i][\"answer\"]))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            l_sample_correct.append(0.0)\n",
    "            continue\n",
    "\n",
    "        l_correct.append(l_sample_correct[0])\n",
    "\n",
    "    return l_correct\n",
    "\n",
    "for example in l_examples:\n",
    "    example['train_acc'] = np.mean(calculate_accuracy(example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a412a1f-de17-4d22-b798-12ea8ce0db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = pd.DataFrame(l_examples)\n",
    "\n",
    "df_viz['encoding_scheme'] = df_viz['data'].map(lambda x: x['experiment_params']['encoding_scheme'])\n",
    "df_viz['model'] = df_viz['data'].map(lambda x: x['experiment_params']['model'])\n",
    "\n",
    "try:\n",
    "    df_viz['model_size'] = df_viz['model'].map(parse_params)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "df_viz['input_type'] = df_viz['data'].map(lambda x: \"_\".join(x['experiment_name'].split(\"_\")[:2]))\n",
    "\n",
    "df_viz['n_few_shot_examples'] = df_viz['data'].map(lambda x: x['experiment_params'].get('n_few_shot_examples', None))\n",
    "try:\n",
    "    df_viz['total_train_tok'] = df_viz['n_total_train_tok'].map(humanize_number)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "df_viz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59da245-a8a4-482d-b5a8-814c663f4cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz['input_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d5f60-3ce3-448f-b887-0d0723e8a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_set = ['math_cot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f00849-cf39-46fb-9ae3-6aa53c9ca93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that train set has all valid inputs\n",
    "df_viz_tmp = df_viz[df_viz['input_type'].isin(filter_set)]\n",
    "\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.sort_values([\n",
    "    'model_size',\n",
    "    'encoding_scheme', \n",
    "    'n_few_shot_examples',\n",
    "    # 'n_total_train_tok'\n",
    "])\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.astype({'n_few_shot_examples': str})\n",
    "\n",
    "fig = px.bar(df_viz_tmp, \n",
    "             x='encoding_scheme',\n",
    "             y='train_acc',\n",
    "             height=600, width=1600,\n",
    "             # height=1600, width=1600,\n",
    "             # color='model',\n",
    "             # color='n_few_shot_examples',\n",
    "             # facet_row='model',\n",
    "             facet_col='model',\n",
    "             color='input_type',\n",
    "             # color='total_train_tok',\n",
    "             # color_discrete_map=color_discrete_map,\n",
    "             barmode=\"group\"\n",
    "            )\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab556b1-e259-4e5f-86cb-2bccbab377bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp = df_viz[df_viz['input_type'].isin(filter_set)]\n",
    "\n",
    "# df_viz_tmp = duckdb.query(\"WITH t1 AS (SELECT model, encoding_scheme, COUNT(*) as ct FROM df_viz_tmp GROUP BY model, encoding_scheme HAVING ct > 1) SELECT * FROM df_viz_tmp WHERE encoding_scheme IN (SELECT encoding_scheme FROM t1)\").to_df()\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.sort_values([\n",
    "    'model_size',\n",
    "    'encoding_scheme', \n",
    "    'n_few_shot_examples',\n",
    "    # 'n_total_train_tok'\n",
    "])\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.astype({'n_few_shot_examples': str})\n",
    "\n",
    "# unique_tokens = df_viz_tmp[['total_train_tok', 'n_total_train_tok']].drop_duplicates()\n",
    "# unique_tokens = unique_tokens.sort_values('n_total_train_tok')['total_train_tok'].tolist()\n",
    "\n",
    "# # Sample evenly from a continuous colormap\n",
    "# colorscale = px.colors.sample_colorscale(\n",
    "#     \"Plasma\",  # <-- You can swap with \"Plasma\", \"Cividis\", etc.\n",
    "#     np.linspace(0, 1, len(unique_tokens))\n",
    "# )\n",
    "\n",
    "# # Create discrete mapping: string label → continuous color\n",
    "# color_discrete_map = dict(zip(unique_tokens, colorscale))\n",
    "\n",
    "fig = px.bar(df_viz_tmp, \n",
    "             x='encoding_scheme',\n",
    "             y='contains_math_solving',\n",
    "             height=600, width=1600,\n",
    "             # height=1600, width=1600,\n",
    "             # color='model',\n",
    "             error_y='contains_math_solving_hi_ci',\n",
    "             error_y_minus='contains_math_solving_low_ci',\n",
    "             # color='n_few_shot_examples',\n",
    "             # facet_row='model',\n",
    "             facet_col='model',\n",
    "             color='input_type',\n",
    "             # color='total_train_tok',\n",
    "             # color_discrete_map=color_discrete_map,\n",
    "             title=\"% of CoT flagged by Qwen3 32B monitor as trying to solve a math problem\",\n",
    "             barmode=\"group\"\n",
    "            )\n",
    "\n",
    "fig.update_yaxes(title=\"% flagged\", dtick=0.05)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5559e93b-ed7e-473a-b1e1-e40b2d723072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp = df_viz[df_viz['input_type'].isin(filter_set)]\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.sort_values([\n",
    "    'model_size',\n",
    "    'encoding_scheme', \n",
    "    'n_few_shot_examples',\n",
    "    # 'n_total_train_tok'\n",
    "])\n",
    "\n",
    "# df_viz_tmp = duckdb.query(\"WITH t1 AS (SELECT model, encoding_scheme, COUNT(*) as ct FROM df_viz_tmp GROUP BY model, encoding_scheme HAVING ct > 1) SELECT df_viz_tmp.* FROM df_viz_tmp INNER JOIN t1 ON t1.model = df_viz_tmp.model AND t1.encoding_scheme = df_viz_tmp.encoding_scheme\").to_df()\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.astype({'n_few_shot_examples': str})\n",
    "\n",
    "# unique_tokens = df_viz_tmp[['total_train_tok', 'n_total_train_tok']].drop_duplicates()\n",
    "# unique_tokens = unique_tokens.sort_values('n_total_train_tok')['total_train_tok'].tolist()\n",
    "\n",
    "# # Sample evenly from a continuous colormap\n",
    "# colorscale = px.colors.sample_colorscale(\n",
    "#     \"Plasma\",  # <-- You can swap with \"Plasma\", \"Cividis\", etc.\n",
    "#     np.linspace(0, 1, len(unique_tokens))\n",
    "# )\n",
    "\n",
    "# # Create discrete mapping: string label → continuous color\n",
    "# color_discrete_map = dict(zip(unique_tokens, colorscale))\n",
    "\n",
    "\n",
    "fig = px.bar(df_viz_tmp, x='encoding_scheme', y='followed_encoding_style',\n",
    "             height=600, width=1600,\n",
    "             # height=1600, width=1600,\n",
    "             # color='model',\n",
    "             error_y='followed_encoding_style_hi_ci',\n",
    "             error_y_minus='followed_encoding_style_low_ci',\n",
    "             # color='n_few_shot_examples',\n",
    "             # facet_row='model',\n",
    "             facet_col='model',\n",
    "             # color='training_augmentation',\n",
    "             # color='total_train_tok',\n",
    "             # color_discrete_map=color_discrete_map,\n",
    "             title=\"Encoding style adherence<br><sup>Adherence determined by prompting Qwen3 32B to compare the model's output to the reference encoded reasoning.\",\n",
    "             barmode=\"group\"\n",
    "            )\n",
    "\n",
    "fig.update_yaxes(title=\"% adherent encodings\", dtick=0.05)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72f4a6-5246-4397-890a-3eb3ded732a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp = df_viz[df_viz['input_type'].isin(filter_set)]\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.sort_values([\n",
    "    'model_size',\n",
    "    'encoding_scheme', \n",
    "    'n_few_shot_examples',\n",
    "    # 'n_total_train_tok'\n",
    "])\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.astype({'n_few_shot_examples': str})\n",
    "\n",
    "# df_viz_tmp = duckdb.query(\"WITH t1 AS (SELECT model, encoding_scheme, COUNT(*) as ct FROM df_viz_tmp GROUP BY model, encoding_scheme HAVING ct > 1) SELECT df_viz_tmp.* FROM df_viz_tmp INNER JOIN t1 ON t1.model = df_viz_tmp.model AND t1.encoding_scheme = df_viz_tmp.encoding_scheme\").to_df()\n",
    "\n",
    "\n",
    "# df_viz_tmp['training_augmentation'] = df_viz_tmp['input_type'].map({\n",
    "#     'math_cot': 'CoT only',\n",
    "#     'mathcot_dataaugmentation': 'fwd+bwd translate + CoT'\n",
    "# })\n",
    "\n",
    "\n",
    "# unique_tokens = df_viz_tmp[['total_train_tok', 'n_total_train_tok']].drop_duplicates()\n",
    "# unique_tokens = unique_tokens.sort_values('n_total_train_tok')['total_train_tok'].tolist()\n",
    "\n",
    "# # Sample evenly from a continuous colormap\n",
    "# colorscale = px.colors.sample_colorscale(\n",
    "#     \"Plasma\",  # <-- You can swap with \"Plasma\", \"Cividis\", etc.\n",
    "#     np.linspace(0, 1, len(unique_tokens))\n",
    "# )\n",
    "\n",
    "# # Create discrete mapping: string label → continuous color\n",
    "# color_discrete_map = dict(zip(unique_tokens, colorscale))\n",
    "\n",
    "fig = px.bar(df_viz_tmp, x='encoding_scheme', y='is_corrects',\n",
    "             height=600, width=1600,\n",
    "             # height=1600, width=1600,\n",
    "             # color='encoding_scheme',\n",
    "             error_y='is_corrects_hi_ci',\n",
    "             error_y_minus='is_corrects_low_ci',\n",
    "             # color='n_few_shot_examples',\n",
    "             # facet_row='model',\n",
    "             # color='training_augmentation',\n",
    "             facet_col='model',\n",
    "             # color='total_train_tok',\n",
    "             # color_discrete_map=color_discrete_map,\n",
    "             title=\"Accuracy, MATH subset\",\n",
    "             barmode=\"group\"\n",
    "            )\n",
    "\n",
    "fig.update_yaxes(title=\"Accuracy\", dtick=0.05)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644330e7-ca98-47a0-8883-6e2d35183649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp = df_viz[df_viz['input_type'].isin(filter_set)]\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.sort_values([\n",
    "    'model_size',\n",
    "    'encoding_scheme', \n",
    "    'n_few_shot_examples'\n",
    "])\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.astype({'n_few_shot_examples': str})\n",
    "\n",
    "fig = px.bar(df_viz_tmp, x='encoding_scheme', y='fully_coherent_and_correct',\n",
    "             height=600, width=1600,\n",
    "             # height=900, width=1600,\n",
    "             color='model',\n",
    "             error_y_minus='fully_coherent_and_correct_low_ci',\n",
    "             error_y='fully_coherent_and_correct_hi_ci',\n",
    "             # color='n_few_shot_examples',\n",
    "             # facet_row='model',\n",
    "             title=\"% of responses correct AND adhered to encoding format AND produced coherent English post-decode, MATH subset\",\n",
    "             barmode=\"group\"\n",
    "            )\n",
    "\n",
    "fig.update_yaxes(title=\"% of responses\", dtick=0.05)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e73ed2-1692-44d7-be3c-2b2e0c30e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp = df_viz[df_viz['input_type'].isin(filter_set)]\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.explode('num_tokens_output')\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.sort_values([\n",
    "    'model_size',\n",
    "    'encoding_scheme', \n",
    "    'n_few_shot_examples'\n",
    "])\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.astype({'n_few_shot_examples': str})\n",
    "\n",
    "\n",
    "fig = px.box(df_viz_tmp, x='encoding_scheme', y='num_tokens_output',\n",
    "             # height=600, width=1600,\n",
    "             height=1600, width=1600,\n",
    "             # color='model',\n",
    "             color='n_few_shot_examples',\n",
    "             facet_row='model',\n",
    "             title=\"# tokens generated, MATH subset, SFT\",\n",
    "            )\n",
    "\n",
    "fig.update_yaxes(title=\"# tokens\", range=[0, 5000], dtick=500)\n",
    "fig.update_traces(marker=dict(opacity=0.08))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd132a-4f07-4354-8aef-ecb744066d02",
   "metadata": {},
   "source": [
    "# Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea91e7cf-1be3-48f0-be20-ce1918c231b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scheme = 'speaking_math_safety_steg'\n",
    "test_model = 'Qwen/Qwen2.5-14B-Instruct'\n",
    "test_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23894a-6e69-4aa1-af84-dbdab60c1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz[(df_viz['model'] == test_model) & (df_viz['encoding_scheme'] == test_scheme)]['reference_problem_df'].iloc[0][test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cecb8de-42aa-4717-9646-64d7528f6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz[(df_viz['model'] == test_model) & (df_viz['encoding_scheme'] == test_scheme)]['reference_solution_df'].iloc[0][test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f92dd3-24db-4bd9-94cf-c25342c3d6fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_viz[(df_viz['model'] == test_model) & (df_viz['encoding_scheme'] == test_scheme)]['model_cot_df'].iloc[0][test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561fed07-320b-47cf-bedd-c2cf7d2af6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_hash = df_viz[(df_viz['model'] == test_model) & (df_viz['encoding_scheme'] == test_scheme)]['experiment_hash'].iloc[0]\n",
    "example_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd34c8-c820-4689-9865-b5287e3fa4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/home/ubuntu/sky_workdir/encoding-schemes/output/{example_hash}/data/sft_model_meta.json\", \"r\") as fp:\n",
    "    d_example = json.load(fp)\n",
    "\n",
    "d_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4a42f-b0d6-4c25-a09c-45c80a4e2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sft = pd.read_parquet(f\"/home/ubuntu/sky_workdir/encoding-schemes/output/{example_hash}/data/sft_train.parquet\")\n",
    "df_sft['messages'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e777b-73e2-409d-9443-837fad99fcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a297dd-9f7f-48df-849b-c13b62e015f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(\"/home/ubuntu/sky_workdir/encoding-schemes/output/52e3d18631a304edc688e3a05e6cc8b3dfa2c4c2/data/joined_output.parquet\")\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89eab75-164e-4232-93ee-67bf3eec9935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[0]['generated_backtranslations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68411181-2e23-456d-8d30-69de84105a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
