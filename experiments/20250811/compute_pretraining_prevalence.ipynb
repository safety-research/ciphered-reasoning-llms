{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63e351-1de9-4e76-9483-c6a72b250265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52358c6-74c1-4210-abf8-f697f638dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/sky_workdir/encoding-schemes\")\n",
    "\n",
    "from encoding_schemes import get_deterministic_adherence_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa89ad7d-3211-4b01-8af2-905f4635af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5798d70-db46-4668-afb1-a7c7dd2be11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "conn_string = os.environ[\"SUPABASE_CONNECTION_URL\"]\n",
    "\n",
    "conn = psycopg2.connect(conn_string)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a92538-37b2-48c1-a57d-3976ceab9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql(\"SELECT * FROM public.encoding_schemes WHERE (data->'experiment_tags'->'sft')::boolean\", conn)\n",
    "\n",
    "# sel_str = \"\"\"\n",
    "# -- redo prompted\n",
    "# (\n",
    "#     (data->'experiment_tags'->'numina_math_cot_rerun')::BOOL\n",
    "#     AND (NOT (data->'force_overwrite')::BOOL OR data->'force_overwrite' IS NULL)\n",
    "#     AND (data->'experiment_name')::TEXT LIKE '%prompted_%'\n",
    "# )\n",
    "# \"\"\"\n",
    "\n",
    "# sel_str = \"\"\"\n",
    "# -- Few shot\n",
    "#  (\n",
    "#      (data->'experiment_tags'->'numina_math_cot_rerun')::BOOL\n",
    "#      AND (NOT (data->'force_overwrite')::BOOL OR data->'force_overwrite' IS NULL)\n",
    "#      AND (\n",
    "#          (data->'experiment_params'->'n_few_shot_examples')::INT = 8\n",
    "#      )\n",
    "#   )\n",
    "# \"\"\"\n",
    "\n",
    "sel_str = \"\"\"\n",
    "-- NuminaMath CoT Rerun\n",
    " (\n",
    "     (data->'experiment_tags'->'numina_math_cot_rerun')::BOOL\n",
    "     AND (NOT (data->'force_overwrite')::BOOL OR data->'force_overwrite' IS NULL)\n",
    "     AND (\n",
    "         (data->'experiment_params'->'sampling_params'->'n')::INT = 4\n",
    "         OR ((data->'experiment_params'->'model')::TEXT LIKE '%gpt%' AND (data->'experiment_params'->'sft_params'->'batch_size')::INT != 48)\n",
    "     )\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "# sel_str = \"\"\"\n",
    "# -- prompted no sft decode\n",
    "# (\n",
    "#     (data->'experiment_tags'->'numina_math_cot_rerun')::BOOL\n",
    "#     AND (NOT (data->'force_overwrite')::BOOL OR data->'force_overwrite' IS NULL)\n",
    "#     AND (data->'experiment_name')::TEXT LIKE '%prompteddecode%'\n",
    "# )\n",
    "# \"\"\"\n",
    "\n",
    "df = pd.read_sql(f\"\"\"\n",
    "SELECT * FROM public.encoding_schemes \n",
    "    WHERE \n",
    "\n",
    "{sel_str}\n",
    "\n",
    "\n",
    "ORDER BY created_at DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "l_examples = df.to_dict('records')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b5015-806c-4995-b403-3a1a0cbc1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "[example for example in l_examples if example[\"data\"][\"experiment_params\"]['encoding_scheme'] == 'speaking_identity' and \"14B\" in example[\"data\"][\"experiment_params\"][\"model\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382227f1-9ba6-412a-b26e-b056e31a5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "\n",
    "l_keep_encoding_schemes = [\n",
    " 'speaking_leet_speak',\n",
    " 'speaking_pirate_speak',\n",
    " 'speaking_yoda_speak',\n",
    " 'speaking_Morse_code',\n",
    " 'speaking_Adyghe',\n",
    " 'speaking_Arabic',\n",
    " 'speaking_French',\n",
    " 'speaking_Python',\n",
    " 'speaking_space_between_chars',\n",
    " 'speaking_base64_2x_cipher',\n",
    " 'speaking_base64_3x_cipher',\n",
    " 'speaking_swap_even_odd_letters_in_each_word',\n",
    " 'speaking_reverse_fibonacci_indices_in_each_word',\n",
    " 'speaking_base64_cipher',\n",
    " 'speaking_reverse_letters_in_each_word',\n",
    " 'speaking_dot_between_chars',\n",
    " 'speaking_rot13_cipher',\n",
    " 'speaking_gzip_to_base64_encoded',\n",
    " 'speaking_letter_to_word_with_dot',\n",
    " 'speaking_reverse_letters_in_each_word',\n",
    " 'speaking_letter_to_word_with_dot',\n",
    " 'speaking_identity']\n",
    "\n",
    "df = df[df['data'].map(lambda x: '14B' in x['experiment_params']['model'])]\n",
    "df = df[df['data'].map(lambda x: x['experiment_name'].startswith('math_cot'))]\n",
    "df = df[df['data'].map(lambda x: x['experiment_params']['encoding_scheme'] in l_keep_encoding_schemes)]\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd784d-5707-4c97-b50b-91a05a24e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/ubuntu/sky_workdir/encoding-schemes/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa28c82-c5ae-42b7-957d-a56c020ea840",
   "metadata": {},
   "source": [
    "# Extract n grams and fetch counts\n",
    "\n",
    "Use Llama 2 tokenizer to match infinigram engine and fetch 5 gram token outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dbf114-4c48-4639-8e73-12d797a40f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f79d2b-b52f-40ca-a29e-d88f9754d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", add_bos_token=False, add_eos_token=False)\n",
    "\n",
    "def extract_ngrams(s, n=5):\n",
    "    tokens = tokenizer.encode(s)\n",
    "\n",
    "    if len(tokens) < n:\n",
    "        return set()\n",
    "\n",
    "    s_ngrams = set()\n",
    "    for i in range(0, len(tokens) - n):\n",
    "        ngram_toks = tokens[i:i+n]\n",
    "        \n",
    "        decoded_str = tokenizer.decode(ngram_toks)\n",
    "        s_ngrams.add(decoded_str)\n",
    "    return s_ngrams\n",
    "\n",
    "@ray.remote\n",
    "def extract_ngrams_df(df, n=5):\n",
    "    s_ngrams = set()\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        s_ngrams = s_ngrams.union(extract_ngrams(row['translated_solution'], n=n))\n",
    "\n",
    "    return s_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7705be0-a963-4027-95b2-f690a47a6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0706e77-5783-4dbb-8b11-18b0689e0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_all(tasks, **kwargs):\n",
    "    return await tqdm_asyncio.gather(*tasks, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793db67-1734-4a51-8d99-b4d95db204d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rate_limit = asyncio.Semaphore(256)\n",
    "\n",
    "async def compute_ngram_for_example(example, n):\n",
    "    df = pd.read_parquet(os.path.join(root_dir, example['experiment_hash'], 'data', \"joined_output.parquet\"))\n",
    "\n",
    "    s_ngrams = ray.get(extract_ngrams_df.remote(df, n=n))\n",
    "    n_occurrences = 0\n",
    "\n",
    "    async def query_infinigram(payload):\n",
    "        async with rate_limit:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                for i in range(1000):\n",
    "                    async with session.post('https://api.infini-gram.io/', json=payload) as resp:\n",
    "                        if resp.status != 200:\n",
    "                            await asyncio.sleep(1 + random.random())\n",
    "                            continue\n",
    "    \n",
    "                        return await resp.json()\n",
    "    \n",
    "                raise RuntimeError(f\"{payload} failed after 10 attempts!\")\n",
    "\n",
    "    l_tasks = []\n",
    "    for ngram in s_ngrams:\n",
    "        l_tasks.append(query_infinigram(\n",
    "            {\n",
    "                'index': 'v4_rpj_llama_s4',\n",
    "                'query_type': 'count',\n",
    "                'query': ngram,\n",
    "            }\n",
    "        ))\n",
    "\n",
    "    # l_tasks = asyncio.run(gather_all(l_tasks))\n",
    "    l_tasks = await gather_all(l_tasks, miniters=1000)\n",
    "\n",
    "    for result in l_tasks:\n",
    "        n_occurrences += result['count']\n",
    "\n",
    "    return n_occurrences\n",
    "\n",
    "# await compute_ngram_for_example(l_examples[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecaf341-c190-47fc-bf03-c9d06ed2ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_n_4grams = []\n",
    "\n",
    "for _, example in df.iterrows():\n",
    "    l_n_4grams.append(await compute_ngram_for_example(example, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f998c89-411a-40fa-9f61-69de0cd1ae2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24628987121,\n",
       " 22929369771,\n",
       " 23814570491,\n",
       " 7348235206,\n",
       " 1146624755,\n",
       " 11085434805,\n",
       " 9723038114,\n",
       " 20964913670,\n",
       " 16199246975,\n",
       " 19458561192,\n",
       " 936726227,\n",
       " 21576376532,\n",
       " 20401655455,\n",
       " 1176270205,\n",
       " 924717530,\n",
       " 20405497376,\n",
       " 927863731,\n",
       " 2501525117,\n",
       " 1298642849,\n",
       " 23964318713]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_n_4grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee7195-b060-4018-86a2-0c8f2646bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for _, example in df.iterrows():\n",
    "    experiment_hash = example['experiment_hash']\n",
    "\n",
    "    with open(os.path.join('/home/ubuntu/sky_workdir/encoding-schemes', 'output', experiment_hash, 'data', 'num_pretraining_4grams_redpajama.json'), 'w') as fp:\n",
    "        json.dump({\n",
    "            'num_occurrences': l_n_4grams[i]\n",
    "        }, fp)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c51c8a-f377-4aa3-be7a-a56506b3ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
