{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d0a44-0aae-4a22-9ea2-552f1efd9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31791de-bdbf-44f4-ac17-de4f754d0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/sky_workdir/encoding-schemes\")\n",
    "\n",
    "from encoding_schemes import get_deterministic_adherence_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8432f-7bb7-4bb8-8223-ea329456a590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8ad9e-91d3-4e3b-b25c-9f19f3e4b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "conn_string = os.environ[\"SUPABASE_CONNECTION_URL\"]\n",
    "\n",
    "conn = psycopg2.connect(conn_string)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b3a2c-ade1-42ca-a798-5b94232485d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_str = \"\"\"\n",
    "-- NuminaMath CoT Rerun\n",
    " (\n",
    "     (data->'experiment_tags'->'numina_math_cot_rerun')::BOOL\n",
    "     AND (NOT (data->'force_overwrite')::BOOL OR data->'force_overwrite' IS NULL)\n",
    "     AND (\n",
    "         (data->'experiment_params'->'sampling_params'->'n')::INT = 4\n",
    "         OR ((data->'experiment_params'->'model')::TEXT LIKE '%gpt%' AND (data->'experiment_params'->'sft_params'->'batch_size')::INT != 48)\n",
    "     )\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(f\"\"\"\n",
    "SELECT * FROM public.encoding_schemes \n",
    "    WHERE \n",
    "\n",
    "{sel_str}\n",
    "\n",
    "\n",
    "ORDER BY created_at DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439f59a-7755-482d-ac55-c324ac5bed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/ubuntu/sky_workdir/encoding-schemes/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d72f27-7ec8-4ffd-b530-f2b0b27cefab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_examples = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef482ac-2bcb-46ad-81d0-1a2e523a92e7",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a81ec-f561-430e-8570-c9d4a2a0f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap_ci(data, statistic=np.mean, alpha=0.05, n_boot=10_000, random_state=None):\n",
    "    \"\"\"\n",
    "    Returns (point_estimate, low_CI, high_CI) for given 1D data.\n",
    "    Works with bool, int, or float data.\n",
    "    \"\"\"\n",
    "    x = np.asarray(data).astype(float)  # ensure numeric\n",
    "    x = x[~np.isnan(x)]\n",
    "    if len(x) == 0:\n",
    "        raise ValueError(\"No valid data for bootstrapping.\")\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(x)\n",
    "\n",
    "    # Draw bootstrap samples\n",
    "    idx = rng.integers(0, n, size=(n_boot, n))\n",
    "    samples = x[idx]\n",
    "\n",
    "    # Apply statistic row-wise\n",
    "    stats = np.apply_along_axis(statistic, 1, samples)\n",
    "\n",
    "    point = statistic(x)\n",
    "    lo = np.percentile(stats, 100 * (alpha / 2))\n",
    "    hi = np.percentile(stats, 100 * (1 - alpha / 2))\n",
    "    return point, lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fb9f9-33d1-4e61-b837-cc8b37219291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def count_tokens_from_messages(s):\n",
    "    try:\n",
    "        return len(encoding.encode(s, disallowed_special=()))\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db9fcc-ffa9-4a77-ad34-88067f4d63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=2, memory=32 * 1024 * 1024 * 1024)\n",
    "def compute_translation_token_count(example, df_data):\n",
    "    sys.path.append(\"/home/ubuntu/sky_workdir/encoding-schemes\")\n",
    "\n",
    "    from orchestration.experiment_meta_saver import compute_experiment_hash\n",
    "    from utils.io_utils import read_large_parquet\n",
    "\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    model = example[\"data\"][\"experiment_params\"][\"model\"]\n",
    "    if \"gpt\" in model or \"claude\" in model:\n",
    "        print(f\"Overriding tokenizer for {model} with gpt-oss 120b tokenizer because it was detected as a GPT/Claude model!\")\n",
    "        model = \"openai/gpt-oss-120b\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "    return df_data['reference_solution'].map(lambda x: len(tokenizer.encode(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f84e71-0f86-4e06-b744-96e3e6a71ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231976a-7a7d-4f2a-90f8-eaa70083c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ci_cols(example, df, col_name, transformation_fn):\n",
    "    s_transformed = transformation_fn(df[col_name])\n",
    "    if np.isscalar(s_transformed) and np.isnan(s_transformed):\n",
    "        print(f\"Warning: {col_name} was all NaN, ignoring!\")\n",
    "        return\n",
    "    mid, lo, hi = bootstrap_ci(s_transformed)\n",
    "    example[col_name] = mid\n",
    "    example[f'{col_name}_low_ci'] = mid - lo\n",
    "    example[f'{col_name}_hi_ci'] = hi - mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1d5fd-3931-4206-a956-9704eae789ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multi_row_transformation(df, row_transform_fn, col_name, agg_fn):\n",
    "    df[col_name] = df.apply(row_transform_fn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73907c00-ce16-4bce-b6e9-14d9bb68e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _score_rollouts(rollouts):\n",
    "    # rollouts: list/array of rollout sequences; may also be None/np.nan/scalar\n",
    "    if rollouts is None or (isinstance(rollouts, float) and np.isnan(rollouts)):\n",
    "        return np.nan\n",
    "\n",
    "    vals = []\n",
    "    for r in rollouts:\n",
    "        # skip None/NaN\n",
    "        if r is None or (isinstance(r, float) and np.isnan(r)):\n",
    "            continue\n",
    "        vals.append(-np.nansum(r))\n",
    "    return np.nanmean(vals) if len(vals) else np.nan\n",
    "\n",
    "\n",
    "def patch_gpt_api_log_loss(example):\n",
    "    experiment_hash = example['experiment_hash']\n",
    "\n",
    "    translation_loss = os.path.join(root_dir, experiment_hash, \"data\", f\"validation_reverse_translation_math500_meta.json\")\n",
    "    with open(translation_loss, \"r\") as fp:\n",
    "        example[\"backtranslation_gt_logprobs\"] = translation_loss[\"valid_loss\"]\n",
    "\n",
    "    # need to be validation loss on 512k...\n",
    "    validation_loss = os.path.join(root_dir, experiment_hash, \"data\", f\"validation_reverse_translation_math500_meta.json\")\n",
    "    with open(validation_loss, \"r\") as fp:\n",
    "        example[\"backtranslation_gt_logprobs\"] = translation_loss[\"valid_loss\"]\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def process_single_example(example):\n",
    "    experiment_hash = example['experiment_hash']\n",
    "    \n",
    "    target_path = os.path.join(root_dir, example['experiment_hash'], \"data\", \"joined_output.parquet\")\n",
    "    if not os.path.exists(target_path):\n",
    "        print(f\"!!!!!! {target_path} missing !!!!!!!\")\n",
    "        return example\n",
    "    \n",
    "    df_data = pd.read_parquet(target_path)\n",
    "\n",
    "    d_col_to_transform = {\n",
    "        'cot_gt_logprobs' : lambda s: np.nansum(s.map(_score_rollouts)),\n",
    "        'generated_cot_is_correct' : np.mean,  # was np.mean\n",
    "        'backtranslation_gt_logprobs' : lambda s: np.nanmean(s.map(_score_rollouts)),\n",
    "        'backtranslation_bleu_scores' : np.mean,  # was np.mean\n",
    "        'generated_cot_adhered_encoding_style': np.mean  # was np.mean\n",
    "    }\n",
    "    for col, fn in d_col_to_transform.items():\n",
    "        if col not in df_data:\n",
    "            print(col)\n",
    "            print(df_data.head())\n",
    "            print(example)\n",
    "            raise Exception(str(col) + \"\\n\" + str(df_data.head()) + \"\\n\" + str(example))\n",
    "\n",
    "        compute_ci_cols(example, df_data, col, fn)\n",
    "\n",
    "    df_data[\"num_tokens_translation_output\"] = ray.get(compute_translation_token_count.remote(example, df_data))\n",
    "\n",
    "    d_and_cols = {\n",
    "        'adherent_and_correct': (\n",
    "            lambda r: np.nanmean( \\\n",
    "                np.array(r['generated_cot_is_correct']).astype(bool) & \\\n",
    "                np.array(r['generated_cot_adhered_encoding_style']).astype(bool) \\\n",
    "            ),\n",
    "            np.nanmean\n",
    "        ),\n",
    "        'total_translation_loss': (\n",
    "            lambda r: np.nanmean( \\\n",
    "                np.array(r['num_tokens_translation_output']) * \\\n",
    "                np.array(np.nanmean(_score_rollouts(r['backtranslation_gt_logprobs'])), dtype=np.float64) \\\n",
    "            ),\n",
    "            np.nanmean\n",
    "        ),\n",
    "    }\n",
    "    for col, (transform_fn, agg_fn) in d_and_cols.items():\n",
    "        compute_multi_row_transformation(df_data, transform_fn, col, agg_fn)\n",
    "        if df_data[col].isna().sum() != len(df_data):\n",
    "            compute_ci_cols(example, df_data, col, lambda x: x)\n",
    "\n",
    "    if \"gpt\" in example[\"data\"][\"experiment_params\"][\"model\"] and \"use_api_sft_model_for_sampling\" in example[\"data\"][\"experiment_params\"]:\n",
    "        with open(os.path.join(root_dir, example['experiment_hash'], \"data\", f\"validation_reverse_translation_math500_meta.json\"), \"r\") as fp:\n",
    "            d_model_meta = json.load(fp)\n",
    "\n",
    "        example[\"backtranslation_gt_logprobs\"] = d_model_meta[\"valid_loss\"]\n",
    "        example[\"total_translation_loss\"] = d_model_meta[\"valid_loss\"] * np.nanmean(df_data[\"num_tokens_translation_output\"])\n",
    "        example[\"total_translation_loss_low_ci\"] = 0.0\n",
    "        example[\"total_translation_loss_hi_ci\"] = 0.0\n",
    "\n",
    "    pretraining_prevalence_path = os.path.join('/home/ubuntu/sky_workdir/encoding-schemes', 'output', experiment_hash, 'data', 'num_pretraining_4grams_redpajama.json')\n",
    "    if os.path.exists(pretraining_prevalence_path):\n",
    "        with open(pretraining_prevalence_path, \"r\") as fp:\n",
    "            d_pretraining_prevalence = json.load(fp)\n",
    "\n",
    "        example[\"pretraining_prevalence\"] = d_pretraining_prevalence[\"num_occurrences\"]\n",
    "\n",
    "    for col in df_data.columns:\n",
    "        example[f\"{col}_df\"] = df_data[col]\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "l_new_examples = [None for _ in range(len(l_examples))]\n",
    "\n",
    "for i, example in tqdm(enumerate(l_examples)):\n",
    "    # l_examples[i] = process_single_example(example)\n",
    "    l_new_examples[i] = process_single_example.remote(example)\n",
    "\n",
    "for i, example in tqdm(enumerate(l_new_examples)):\n",
    "    try:\n",
    "        l_new_examples[i] = ray.get(example)\n",
    "    except ray.exceptions.RayTaskError as e:\n",
    "        l_new_examples[i] = l_examples[i]\n",
    "        print(e)\n",
    "\n",
    "l_examples = l_new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7b0cc-4d72-4780-9f3a-0fa25ee3a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize_number(num: float) -> str:\n",
    "    \"\"\"\n",
    "    Converts a number into a human-readable string with k, M, or B suffixes.\n",
    "    \n",
    "    Args:\n",
    "        num (float): The number to format.\n",
    "    \n",
    "    Returns:\n",
    "        str: Human-readable string representation.\n",
    "    \"\"\"\n",
    "    if num >= 1_000_000_000:\n",
    "        return f\"{num / 1_000_000_000:.1f}B\"\n",
    "    elif num >= 1_000_000:\n",
    "        return f\"{num / 1_000_000:.1f}M\"\n",
    "    elif num >= 1_000:\n",
    "        return f\"{num / 1_000:.1f}k\"\n",
    "    else:\n",
    "        return str(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c8aa3-b7b1-48a7-b0fc-c8811fe9a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_params(model):\n",
    "    if 'gpt' in model:\n",
    "        if 'nano' in model:\n",
    "            return 0\n",
    "        elif 'mini' in model:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "\n",
    "    if 'claude' in model:\n",
    "        if 'haiku' in model:\n",
    "            return 3\n",
    "        elif '3-opus' in model:\n",
    "            return 4\n",
    "        elif '3-5' in model:\n",
    "            return 5\n",
    "        elif 'sonnet-4' in model:\n",
    "            return 6\n",
    "        else:\n",
    "            return 7\n",
    "    \n",
    "    return int(re.search(\"([0-9]+)B\", model).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a412a1f-de17-4d22-b798-12ea8ce0db67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_viz = pd.DataFrame(l_examples)\n",
    "\n",
    "orig_len = len(df_viz)\n",
    "\n",
    "# df_viz = df_viz[df_viz['cot_gt_logprobs'].notna()]\n",
    "\n",
    "new_len = len(df_viz)\n",
    "if orig_len != new_len:\n",
    "    print(f\"Lost {orig_len - new_len} examples from na logprobs\")\n",
    "\n",
    "df_viz['encoding_scheme'] = df_viz['data'].map(lambda x: x['experiment_params']['encoding_scheme'])\n",
    "df_viz['model'] = df_viz['data'].map(lambda x: x['experiment_params']['model'])\n",
    "\n",
    "try:\n",
    "    df_viz['model_size'] = df_viz['model'].map(parse_params)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "df_viz['input_type'] = df_viz['data'].map(lambda x: \"_\".join(x['experiment_name'].split(\"_\")[:2]))\n",
    "\n",
    "df_viz['n_few_shot_examples'] = df_viz['data'].map(lambda x: x['experiment_params'].get('n_few_shot_examples', None))\n",
    "\n",
    "df_viz['Adherence Calculation Method'] = df_viz['encoding_scheme'].map(lambda x: get_deterministic_adherence_fn(x, None) is not None).map({ True: 'deterministic', False: 'Sonnet 4 judge'})\n",
    "\n",
    "try:\n",
    "    df_viz['total_train_tok'] = df_viz['n_total_train_tok'].map(humanize_number)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d5f60-3ce3-448f-b887-0d0723e8a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_set = ['math_cot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294af9ce-482f-4336-a8bc-6aaf90027383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp = df_viz[df_viz['input_type'].isin(filter_set)]\n",
    "df_viz_tmp = df_viz_tmp[df_viz_tmp['model'] != 'Qwen/Qwen2.5-7B']\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.sort_values([\n",
    "    'model_size',\n",
    "    'adherent_and_correct'\n",
    "])\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.astype({'n_few_shot_examples': str})\n",
    "\n",
    "df_viz_tmp['encoding_scheme'] = df_viz_tmp['encoding_scheme'].map(lambda s: s.split(\"speaking_\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a828d6-6815-4381-b995-20982640f527",
   "metadata": {},
   "source": [
    "# Paper plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea4d31-60d6-443c-8d80-a06febf33739",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mapping = {\n",
    "    \"baseline\": [\"zero_shot\", \"identity\"],\n",
    "    \"letter mutation\": [\n",
    "        \"reverse_letters_in_each_word\",\n",
    "        \"swap_even_odd_letters_in_each_word\",\n",
    "        \"reverse_fibonacci_indices_in_each_word\",\n",
    "        \"letter_to_word_with_dot\",\n",
    "        \"dot_between_chars\",\n",
    "        \"space_between_chars\",\n",
    "    ],\n",
    "    \"language deletion\": [\"remove_all_verbs\", \"remove_all_nouns\"],\n",
    "    \"language translation\": [\n",
    "        \"French\",\"Chinese\",\"Korean\",\"Russian\",\"Arabic\",\"Adyghe\",\n",
    "        \"Morse_code\",\"Python\",\"enterprise_Java\",\n",
    "    ],\n",
    "    \"algorithmic cipher\": [\n",
    "        \"rot13_cipher\",\"base64_cipher\",\"base64_2x_cipher\",\n",
    "        \"base64_3x_cipher\",\"caesar_cipher\",\"gzip_to_base64_encoded\",\n",
    "    ],\n",
    "    \"themed reasoning\": [\n",
    "        \"paraphrase_naive\",\n",
    "        \"pirate_speak\",\n",
    "        \"leet_speak\",\n",
    "        \"yoda_speak\",\n",
    "        \"shakespearean_text\",\n",
    "    ],\n",
    "    \"extraneous content\": [\n",
    "        \"insert_tweet\",\n",
    "        \"python_snippet_comment\",\n",
    "        \"croissant_news_article\",\n",
    "        \"math_textbook_article\",\n",
    "        \"five_emojis\",\n",
    "    ],\n",
    "    \"delete inf.\": [\n",
    "        \"replace_math_content_with_black_box\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "l_themed_encodings = [\n",
    "    \"remove_all_verbs\",\n",
    "    \"paraphrase_naive\",\n",
    "    \"pirate_speak\",\n",
    "    \"leet_speak\",\n",
    "    \"yoda_speak\",\n",
    "    \"shakespearean_text\",\n",
    "    \"insert_tweet\",\n",
    "    \"python_snippet_comment\",\n",
    "    \"croissant_news_article\",\n",
    "    \"math_textbook_article\",\n",
    "    \"five_emojis\",\n",
    "    \"replace_math_content_with_black_box\",\n",
    "    \"reverse_letters_in_each_word_no_math_expressions\",\n",
    "    \"reverse_letters_in_each_word_only_math_expressions\"\n",
    "]\n",
    "\n",
    "l_ignore_languages = [\n",
    "    \"Russian\",\n",
    "    \"Chinese\",\n",
    "    # \"Korean\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b0308-1806-4005-80ec-d83ab4716125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.colors as pc\n",
    "\n",
    "def sample_colorscale(colorscale_name: str, n: int):\n",
    "    \"\"\"\n",
    "    Sample N equally spaced hex colors from a Plotly continuous colorscale.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    colorscale_name : str\n",
    "        Name of a Plotly built-in continuous colorscale (e.g., \"Viridis\", \"Blues\").\n",
    "    n : int\n",
    "        Number of samples to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        List of hex color strings.\n",
    "    \"\"\"\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be >= 1\")\n",
    "    colorscale = px.colors.get_colorscale(colorscale_name)\n",
    "    # equally spaced points in [0,1]\n",
    "    vals = [i/(n-1) if n > 1 else 0.5 for i in range(n)]\n",
    "    return [pc.sample_colorscale(colorscale, v)[0] for v in vals]\n",
    "\n",
    "l_gpt_gradient = sample_colorscale(\"Emrld\", 4 + 1)\n",
    "d_gpt_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['gpt-4.1-nano-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-2025-04-14', 'gpt-5-chat-latest'],\n",
    "        l_gpt_gradient[:-1]\n",
    "    )\n",
    "}\n",
    "\n",
    "l_claude_gradient = sample_colorscale(\"Purpor\", 3 + 1)\n",
    "d_claude_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['claude-3-opus-20240229', 'claude-3-5-sonnet-20241022', 'claude-sonnet-4-20250514'],\n",
    "        l_claude_gradient[1:]\n",
    "    )\n",
    "}\n",
    "\n",
    "l_qwen_gradient = sample_colorscale(\"Oryel\", 3 + 1)\n",
    "d_qwen_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['Qwen2.5-3B-Instruct', 'Qwen2.5-7B-Instruct', 'Qwen2.5-14B-Instruct'],\n",
    "        l_qwen_gradient[1:]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbea54-0ca9-49b4-a54c-12699bd2d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_star_encodings = [\n",
    "    \"reverse_letters_in_each_word\",\n",
    "    \"rot13_cipher\",\n",
    "    \"caesar_cipher\", # TODO check\n",
    " 'reverse_fibonacci_indices_in_each_word', # TODO check\n",
    " 'swap_even_odd_letters_in_each_word', # TODO check\n",
    "    \"Morse_code\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e2ffbe-0a88-412a-84ba-ef78415e4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_fixed_encoding_ordering = [\n",
    "    # GPT\n",
    " 'identity',\n",
    "'dot between chars',\n",
    " 'rot13 cipher',\n",
    " 'Korean',\n",
    " 'reverse letters in each word',\n",
    " 'letter to word with dot',\n",
    "     'base64 cipher',\n",
    " # 'remove all verbs',\n",
    "\n",
    "    # placeholder for an empty space\n",
    "    '',\n",
    "\n",
    "    # Qwen/Claude\n",
    "'space between chars',\n",
    " 'Arabic',\n",
    " 'caesar cipher',\n",
    " 'French',\n",
    " 'Adyghe',\n",
    " 'Morse code',\n",
    " 'Python',\n",
    " 'reverse fibonacci indices in each word',\n",
    " 'swap even odd letters in each word',\n",
    " 'base64 3x cipher',\n",
    " 'base64 2x cipher',\n",
    " 'remove all nouns',\n",
    " 'enterprise Java',\n",
    " 'gzip to base64 encoded'\n",
    " \n",
    "]\n",
    "\n",
    "l_fixed_encoding_ordering = [s.replace(' ', '_') for s in l_fixed_encoding_ordering]\n",
    "\n",
    "for i in range(len(l_fixed_encoding_ordering)):\n",
    "    if l_fixed_encoding_ordering[i] in l_star_encodings:\n",
    "        l_fixed_encoding_ordering[i] += \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9868af0-27d2-4e49-b1fe-5a4aa97dd5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "def make_encoding_scheme_bar_plot(\n",
    "    df,\n",
    "    y_col=\"generated_cot_is_correct\",\n",
    "    title=\"MATH 500 Accuracy\",\n",
    "    y_axis_title=\"Accuracy\",\n",
    "    x_col=\"encoding_scheme\",\n",
    "    model_col=\"model\",\n",
    "    d_mapping=None,\n",
    "    yaxis_dtick=0.1,\n",
    "    show_text=True,\n",
    "    model_order=None,\n",
    "    font_family=\"Inter, Arial\",\n",
    "    sort_by_col=None,\n",
    "    sort_agg=\"max\",\n",
    "    sort_desc=True\n",
    "):\n",
    "    # --- 1) DEFAULT SECTION MAP ---\n",
    "    if d_mapping is None:\n",
    "        d_mapping = {\n",
    "            \"Baselines\": [\n",
    "                \"identity\",\n",
    "                \"zero_shot\",\n",
    "            ],\n",
    "            \"Stylistic text\": [\n",
    "                \"paraphrase_naive\",\n",
    "                \"pirate_speak\",\n",
    "                \"yoda_speak\",\n",
    "                \"shakespearean_text\",\n",
    "            ],\n",
    "            \"Distractors\": [\n",
    "                \"insert_tweet\",\n",
    "                \"python_snippet_comment\",\n",
    "            ],\n",
    "            \"Language\": [\n",
    "                \"leet_speak\",\n",
    "                \"rot13_cipher\",\n",
    "                \"Morse_code\"\n",
    "            ],\n",
    "            \"Inf. content\": [\n",
    "                \"replace_math_content_with_black_box\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    l_color_categories = [\"Language\", \"Inf. content\"]\n",
    "\n",
    "    df_plot = df.copy()\n",
    "\n",
    "    # --- 2) ORDERING BY d_mapping ---\n",
    "    full_category_order, section_spans = [], []\n",
    "    present_set = set(df_plot[x_col].unique())\n",
    "    cursor = 0\n",
    "    \n",
    "    # Create a mapping of encoding schemes to their sections\n",
    "    scheme_to_section = {}\n",
    "    for section_name, schemes in d_mapping.items():\n",
    "        for scheme in schemes:\n",
    "            scheme_to_section[scheme] = section_name\n",
    "\n",
    "    # Use the order defined in d_mapping directly\n",
    "    for section_name, schemes in d_mapping.items():\n",
    "        # Keep only schemes that are present in the data, but maintain their order\n",
    "        present = [s for s in schemes if s in present_set]\n",
    "        if not present:\n",
    "            continue\n",
    "\n",
    "        start = cursor\n",
    "        full_category_order.extend(present)\n",
    "        cursor = len(full_category_order)\n",
    "        end = cursor - 1\n",
    "        section_spans.append((start, end, section_name))\n",
    "\n",
    "    if not full_category_order:\n",
    "        full_category_order = list(df_plot[x_col].unique())\n",
    "        section_spans = [(0, len(full_category_order) - 1, \"All\")]\n",
    "\n",
    "    df_plot[x_col] = pd.Categorical(df_plot[x_col], categories=full_category_order, ordered=True)\n",
    "\n",
    "    # --- PRESERVE MODEL ORDER ---\n",
    "    if model_order is None:\n",
    "        model_order = list(dict.fromkeys(df_plot[model_col]))\n",
    "    df_plot[model_col] = pd.Categorical(df_plot[model_col], categories=model_order, ordered=True)\n",
    "\n",
    "    # --- ERROR BARS ---\n",
    "    err_hi_col = f\"{y_col}_hi_ci\"\n",
    "    err_lo_col = f\"{y_col}_low_ci\"\n",
    "    error_y = err_hi_col if err_hi_col in df_plot.columns else None\n",
    "    error_y_minus = err_lo_col if err_lo_col in df_plot.columns else None\n",
    "\n",
    "    def prettify(s: str) -> str:\n",
    "        s = s.replace(\"_\", \"<br>\")\n",
    "        return s\n",
    "\n",
    "    # --- DETECT WHETHER Y-VALUES ARE PERCENTAGES ---\n",
    "    y_min, y_max = df_plot[y_col].min(), df_plot[y_col].max()\n",
    "    is_percent = y_max <= 1.0 and y_min >= 0.0\n",
    "\n",
    "    if yaxis_dtick is None:\n",
    "        yaxis_dtick = 0.1 if is_percent else None\n",
    "    \n",
    "    # --- CREATE COLOR MAPPINGS ---\n",
    "    # Assuming you have these dictionaries defined elsewhere\n",
    "    # If not, you'll need to define them\n",
    "    original_colors = {**d_qwen_gradient, **d_gpt_gradient}\n",
    "    \n",
    "    # Convert colors to greyscale for non-colored categories\n",
    "    import plotly.colors as pc\n",
    "    \n",
    "    def to_greyscale(color_str):\n",
    "        \"\"\"Convert a color to greyscale, handles both hex and rgb(r,g,b) formats\"\"\"\n",
    "        import re\n",
    "        \n",
    "        # Check if it's an rgb string\n",
    "        rgb_match = re.match(r'rgb\\((\\d+),\\s*(\\d+),\\s*(\\d+)\\)', color_str)\n",
    "        if rgb_match:\n",
    "            r, g, b = map(int, rgb_match.groups())\n",
    "        # Check if it's hex format\n",
    "        elif color_str.startswith('#'):\n",
    "            import plotly.colors as pc\n",
    "            rgb = pc.hex_to_rgb(color_str)\n",
    "            r, g, b = rgb\n",
    "        else:\n",
    "            raise Exception()\n",
    "        \n",
    "        # Use luminance formula to convert to greyscale\n",
    "        grey_val = int(0.299 * r + 0.587 * g + 0.114 * b)\n",
    "        return f'rgb({grey_val}, {grey_val}, {grey_val})'\n",
    "\n",
    "    \n",
    "    # Create the figure using graph_objects for more control\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add traces for each model\n",
    "    for model in model_order:\n",
    "        model_data = df_plot[df_plot[model_col] == model].sort_values(x_col)\n",
    "        \n",
    "        # Prepare colors for each bar\n",
    "        colors = []\n",
    "        for scheme in model_data[x_col]:\n",
    "            section = scheme_to_section.get(scheme, \"\")\n",
    "            colors.append(original_colors[model])\n",
    "            # if section in l_color_categories:\n",
    "            #     # Use original color\n",
    "            #     colors.append(original_colors[model])\n",
    "            # else:\n",
    "            #     # Use greyscale version\n",
    "            #     original_color = original_colors[model]\n",
    "            #     colors.append(to_greyscale(original_color))\n",
    "        \n",
    "        # Add error bars if available\n",
    "        error_y_dict = None\n",
    "        if error_y and error_y_minus:\n",
    "            error_y_dict = dict(\n",
    "                type='data',\n",
    "                symmetric=False,\n",
    "                array=model_data[err_hi_col] if err_hi_col in model_data.columns else None,\n",
    "                arrayminus=model_data[err_lo_col] if err_lo_col in model_data.columns else None\n",
    "            )\n",
    "\n",
    "        l_text = [f\"-{(1 - d) * 100 :.0f}%\" for d in model_data[y_col]]\n",
    "        l_text = [f\"<b><span style='color:blue'>{t}</span></b>\" if 1 - d > 0.2 and encoding != 'zero_shot' else \"\" for t, d, encoding in zip(l_text, model_data[y_col], model_data['encoding_scheme'])]\n",
    "        fig.add_trace(go.Bar(\n",
    "            name=model,\n",
    "            x=model_data[x_col],\n",
    "            y=model_data[y_col],\n",
    "            marker_color=colors,\n",
    "            # error_y=error_y_dict,\n",
    "            text=l_text if show_text else None,\n",
    "            # texttemplate=\"%{y:.0%}\" if (is_percent and show_text) else \"%{y:}\" if show_text else None,\n",
    "            textposition=\"outside\" if show_text else \"none\",\n",
    "        ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        template=\"plotly_white\",\n",
    "        height=500,\n",
    "        width=1500,\n",
    "        barmode=\"group\",\n",
    "        bargap=0.15,\n",
    "        bargroupgap=0.05,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.08,\n",
    "            xanchor=\"left\",\n",
    "            x=0.01,\n",
    "            font=dict(size=18)\n",
    "        ),\n",
    "        margin=dict(t=0, r=0, b=0, l=0),\n",
    "        font=dict(family=font_family, size=15),\n",
    "        title_font=dict(size=22)\n",
    "    )\n",
    "    \n",
    "    # Y axis\n",
    "    if is_percent:\n",
    "        fig.update_yaxes(\n",
    "            title=y_axis_title,\n",
    "            tickformat=\".0%\",\n",
    "            tickmode=\"linear\",\n",
    "            dtick=yaxis_dtick,\n",
    "            rangemode=\"tozero\"\n",
    "        )\n",
    "    else:\n",
    "        fig.update_yaxes(\n",
    "            title=y_axis_title,\n",
    "            tickmode=\"linear\",\n",
    "            rangemode=\"tozero\",\n",
    "            dtick=yaxis_dtick\n",
    "        )\n",
    "    \n",
    "    # X axis\n",
    "    fig.update_xaxes(\n",
    "        title=\"Encoding scheme\",\n",
    "        ticktext=[f\"<b>{prettify(lbl)}</b>\" for lbl in full_category_order],\n",
    "        tickvals=full_category_order,\n",
    "        tickangle=0,\n",
    "        tickfont=dict(size=15)\n",
    "    )\n",
    "    \n",
    "    # --- SECTION BACKGROUNDS + LABELS ---\n",
    "    N = len(full_category_order)\n",
    "    \n",
    "    def to_xdomain(idx):\n",
    "        return idx / N\n",
    "    \n",
    "    shapes = []\n",
    "    annotations = []\n",
    "    for i, (start_idx, end_idx, name) in enumerate(section_spans):\n",
    "        x0 = to_xdomain(start_idx)\n",
    "        x1 = to_xdomain(end_idx + 1)\n",
    "        band = dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x domain\", yref=\"paper\",\n",
    "            x0=x0, x1=x1, y0=0, y1=1,\n",
    "            layer=\"between\",\n",
    "            line=dict(width=0),\n",
    "            fillcolor=\"#C4D8E2\" if i >= 3 else \"rgba(0,0,0,0.03)\" if i % 2 == 0 else \"rgba(0,0,0,0.00)\"\n",
    "        )\n",
    "        shapes.append(band)\n",
    "        annotations.append(dict(\n",
    "            x=(x0 + x1) / 2, xref=\"x domain\",\n",
    "            y=1.1, yref=\"paper\",\n",
    "            text=name, showarrow=False,\n",
    "            font=dict(size=18, color=\"black\"),\n",
    "            xanchor=\"center\"\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(shapes=shapes)\n",
    "    for a in annotations:\n",
    "        fig.add_annotation(**a)\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c09ea1-4fe5-45ce-8ed8-c4b65b83f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute PGR (percent of identity performance) ---\n",
    "df_pgr = df_viz_tmp.copy()\n",
    "\n",
    "# df_pgr = df_pgr[~( (df_pgr['input_type'] == 'mathcot_fewshot') & (df_pgr['encoding_scheme'] == 'identity') )]\n",
    "\n",
    "\n",
    "df_pgr['model'] = df_pgr['model'].str.split('Qwen/').str[-1]\n",
    "\n",
    "# df_pgr = df_pgr[~df_pgr['model'].str.contains('gpt')]\n",
    "# df_pgr = df_pgr[df_pgr['model'].str.contains('14B')]\n",
    "\n",
    "# Identity baseline per model\n",
    "identity_baseline = (\n",
    "    df_pgr[df_pgr[\"encoding_scheme\"] == \"identity\"]\n",
    "    .set_index(\"model\")[\"adherent_and_correct\"]\n",
    ")\n",
    "\n",
    "df_pgr[\"identity_value\"] = np.maximum(df_pgr[\"model\"].map(identity_baseline), 0.0001)\n",
    "\n",
    "# Avoid divide-by-zero\n",
    "# df_pgr = df_pgr[df_pgr[\"identity_value\"] > 0].copy()\n",
    "\n",
    "# Mean PGR as percentage\n",
    "df_pgr[\"PGR_pct\"] = (df_pgr[\"adherent_and_correct\"] / df_pgr[\"identity_value\"])\n",
    "\n",
    "# CI deltas -> percentage deltas relative to identity baseline\n",
    "# low is negative, high is positive\n",
    "df_pgr[\"PGR_pct_hi_ci\"]  = (df_pgr[\"adherent_and_correct_hi_ci\"] / df_pgr[\"identity_value\"])\n",
    "df_pgr[\"PGR_pct_low_ci\"] = (df_pgr[\"adherent_and_correct_low_ci\"]        / df_pgr[\"identity_value\"])\n",
    "\n",
    "df_pgr.loc[df_pgr[\"encoding_scheme\"] == \"identity\", [\"PGR_pct_hi_ci\", \"PGR_pct_low_ci\"]] = 0.0\n",
    "\n",
    "fig = make_encoding_scheme_bar_plot(\n",
    "    df=df_pgr[df_pgr['model'].str.contains('Qwen')],\n",
    "    # df=df_pgr[df_pgr['model'] == 'gpt-4.1-2025-04-14'],\n",
    "    y_col=\"PGR_pct\",\n",
    "    # title=\"Relative % of responses adherent & correct vs. identity encoding\",\n",
    "    title=None,\n",
    "    y_axis_title=\"% of identity adherent & correct\",\n",
    "    yaxis_dtick=0.1,\n",
    "    sort_by_col=\"adherent_and_correct\"\n",
    ")\n",
    "\n",
    "fig.update_yaxes(range=[0.0, 1.0])\n",
    "fig.update_xaxes(title=\"Cipher\")\n",
    "# fig.update_yaxes(range=[0.0, 0.35], dtick=0.05)\n",
    "# fig.update_layout(height=475)\n",
    "# fig.update_traces(width=0.5)\n",
    "fig.update_layout(font=dict(size=24))\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickfont=dict(\n",
    "            size=18,         # Specify the font size\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(title_font=dict(size=20), tickfont=dict(size=18))\n",
    ")\n",
    "\n",
    "fig.add_hline(y=1)\n",
    "\n",
    "# fig.update_traces(textfont_size=15)\n",
    "\n",
    "plotly.io.write_image(fig, 'sft_ablations.pdf', format='pdf')\n",
    "\n",
    "fig.show('png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbfac5-2cb8-40a8-b994-4aeed2fccdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def df_to_latex_table(df_pgr,\n",
    "                      caption=\"Model results\",\n",
    "                      label=\"tab:model-results\",\n",
    "                      percent_decimals=1,\n",
    "                      float_decimals=2):\n",
    "    from io import StringIO\n",
    "\n",
    "    # 1) Build df_export\n",
    "    df_export = df_pgr.copy()\n",
    "\n",
    "    df_export['encoding_scheme'] = df_export['encoding_scheme'].str.replace('_', ' ')\n",
    "    df_export['encoding_scheme'] = df_export['encoding_scheme'].map(\n",
    "        lambda x: 'direct answering' if x == 'zero shot' else x\n",
    "    )\n",
    "\n",
    "    df_export = df_export[\n",
    "        ['model', 'encoding_scheme', 'PGR_pct', 'generated_cot_is_correct',\n",
    "         'generated_cot_adhered_encoding_style', 'backtranslation_bleu_scores',\n",
    "         'Adherence Calculation Method']\n",
    "    ].rename(columns={\n",
    "        'encoding_scheme': 'encoding scheme',\n",
    "        'PGR_pct': '\\\\% of identity adherent + coherent',\n",
    "        'generated_cot_is_correct': 'MATH500 accuracy',\n",
    "        'generated_cot_adhered_encoding_style': 'cipher adherence',\n",
    "        'backtranslation_bleu_scores': 'translation BLEU',\n",
    "    })\n",
    "\n",
    "    # 2) Format numbers\n",
    "    df_fmt = df_export.copy()\n",
    "\n",
    "    col_pct = '\\\\% of identity adherent + coherent'\n",
    "    if pd.api.types.is_numeric_dtype(df_fmt[col_pct]):\n",
    "        s = df_fmt[col_pct].astype(float)\n",
    "        if np.nanmax(s.values) <= 1.5:  # treat as fraction\n",
    "            s = s * 100.0\n",
    "        df_fmt[col_pct] = s.map(lambda x: (f\"{x:.{percent_decimals}f}\\\\%\" if pd.notna(x) else \"\"))\n",
    "\n",
    "    numeric_cols = [\n",
    "        'MATH500 accuracy',\n",
    "        'cipher adherence',\n",
    "        'translation BLEU',\n",
    "    ]\n",
    "    for c in numeric_cols:\n",
    "        if c in df_fmt.columns and pd.api.types.is_numeric_dtype(df_fmt[c]):\n",
    "            df_fmt[c] = df_fmt[c].map(lambda x: (f\"{x:.{float_decimals}f}\" if pd.notna(x) else \"\"))\n",
    "\n",
    "    # 3) Build LaTeX manually with tabularx\n",
    "    buffer = StringIO()\n",
    "    col_names = df_fmt.columns.tolist()\n",
    "\n",
    "    # Choose alignments: first two + last = text (wrap), others numeric\n",
    "    col_spec = \" | \".join([\"p{\" + f\"{0.75 / len(col_names):.2f}\" + \"\\\\linewidth}\" for _ in range(len(col_names))])\n",
    "\n",
    "    # Write header\n",
    "    buffer.write(\"\\\\begin{longtable}[]\")\n",
    "    buffer.write(\"{\" + col_spec + \"}\\n\")\n",
    "\n",
    "    # Column headers\n",
    "    buffer.write(\" & \".join(col_names) + \" \\\\\\\\\\n\")\n",
    "    buffer.write(\"\\\\hline\\n\")\n",
    "\n",
    "    # Rows\n",
    "    for _, row in df_fmt.iterrows():\n",
    "        buffer.write(\" & \".join(str(x) for x in row.tolist()) + \" \\\\\\\\\\n\")\n",
    "\n",
    "    buffer.write(\"\\\\caption{\" + caption + \"}\\n\")\n",
    "    buffer.write(\"\\\\label{\" + label + \"}\\n\")\n",
    "    buffer.write(\"\\\\end{longtable}\\n\")\n",
    "\n",
    "    latex = buffer.getvalue()\n",
    "    print(latex)\n",
    "    return latex\n",
    "\n",
    "\n",
    "\n",
    "df_to_latex_table(df_pgr[df_pgr['PGR_pct'].notna() & df_pgr['model'].str.contains('Qwen') & df_pgr['encoding_scheme'].isin(\n",
    "[\n",
    "                    \"paraphrase_naive\",\n",
    "                \"pirate_speak\",\n",
    "                \"yoda_speak\",\n",
    "                \"shakespearean_text\",\n",
    "                \"insert_tweet\",\n",
    "                \"python_snippet_comment\",\n",
    "                \"leet_speak\",\n",
    "                \"replace_math_content_with_black_box\"\n",
    "    ]\n",
    ")\n",
    "    ], caption=\"TODO CAPTION\", label=\"detailed_sft_results_table\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05ad59-a22a-454e-9699-d31c48e98971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
