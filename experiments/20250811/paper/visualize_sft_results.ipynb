{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d0a44-0aae-4a22-9ea2-552f1efd9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31791de-bdbf-44f4-ac17-de4f754d0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/sky_workdir/encoding-schemes\")\n",
    "\n",
    "from encoding_schemes import get_deterministic_adherence_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8432f-7bb7-4bb8-8223-ea329456a590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8ad9e-91d3-4e3b-b25c-9f19f3e4b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "conn_string = os.environ[\"SUPABASE_CONNECTION_URL\"]\n",
    "\n",
    "conn = psycopg2.connect(conn_string)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b3a2c-ade1-42ca-a798-5b94232485d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_str = \"\"\"\n",
    "-- NuminaMath CoT Rerun\n",
    " (\n",
    "     (data->'experiment_tags'->'numina_math_cot_rerun')::BOOL\n",
    "     AND (NOT (data->'force_overwrite')::BOOL OR data->'force_overwrite' IS NULL)\n",
    "     AND (\n",
    "         (data->'experiment_params'->'sampling_params'->'n')::INT = 4\n",
    "         OR ((data->'experiment_params'->'model')::TEXT LIKE '%gpt%' AND (data->'experiment_params'->'sft_params'->'batch_size')::INT != 48)\n",
    "     )\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(f\"\"\"\n",
    "SELECT * FROM public.encoding_schemes \n",
    "    WHERE \n",
    "\n",
    "{sel_str}\n",
    "\n",
    "\n",
    "ORDER BY created_at DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439f59a-7755-482d-ac55-c324ac5bed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/ubuntu/sky_workdir/encoding-schemes/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d72f27-7ec8-4ffd-b530-f2b0b27cefab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_examples = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef482ac-2bcb-46ad-81d0-1a2e523a92e7",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a81ec-f561-430e-8570-c9d4a2a0f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap_ci(data, statistic=np.mean, alpha=0.05, n_boot=10_000, random_state=None):\n",
    "    \"\"\"\n",
    "    Returns (point_estimate, low_CI, high_CI) for given 1D data.\n",
    "    Works with bool, int, or float data.\n",
    "    \"\"\"\n",
    "    x = np.asarray(data).astype(float)  # ensure numeric\n",
    "    x = x[~np.isnan(x)]\n",
    "    if len(x) == 0:\n",
    "        raise ValueError(\"No valid data for bootstrapping.\")\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(x)\n",
    "\n",
    "    # Draw bootstrap samples\n",
    "    idx = rng.integers(0, n, size=(n_boot, n))\n",
    "    samples = x[idx]\n",
    "\n",
    "    # Apply statistic row-wise\n",
    "    stats = np.apply_along_axis(statistic, 1, samples)\n",
    "\n",
    "    point = statistic(x)\n",
    "    lo = np.percentile(stats, 100 * (alpha / 2))\n",
    "    hi = np.percentile(stats, 100 * (1 - alpha / 2))\n",
    "    return point, lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fb9f9-33d1-4e61-b837-cc8b37219291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def count_tokens_from_messages(s):\n",
    "    try:\n",
    "        return len(encoding.encode(s, disallowed_special=()))\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db9fcc-ffa9-4a77-ad34-88067f4d63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=2, memory=32 * 1024 * 1024 * 1024)\n",
    "def compute_translation_token_count(example, df_data):\n",
    "    sys.path.append(\"/home/ubuntu/sky_workdir/encoding-schemes\")\n",
    "\n",
    "    from orchestration.experiment_meta_saver import compute_experiment_hash\n",
    "    from utils.io_utils import read_large_parquet\n",
    "\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    model = example[\"data\"][\"experiment_params\"][\"model\"]\n",
    "    if \"gpt\" in model or \"claude\" in model:\n",
    "        print(f\"Overriding tokenizer for {model} with gpt-oss 120b tokenizer because it was detected as a GPT/Claude model!\")\n",
    "        model = \"openai/gpt-oss-120b\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "    return df_data['reference_solution'].map(lambda x: len(tokenizer.encode(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f84e71-0f86-4e06-b744-96e3e6a71ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231976a-7a7d-4f2a-90f8-eaa70083c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ci_cols(example, df, col_name, transformation_fn):\n",
    "    s_transformed = transformation_fn(df[col_name])\n",
    "    if np.isscalar(s_transformed) and np.isnan(s_transformed):\n",
    "        print(f\"Warning: {col_name} was all NaN, ignoring!\")\n",
    "        return\n",
    "    mid, lo, hi = bootstrap_ci(s_transformed)\n",
    "    example[col_name] = mid\n",
    "    example[f'{col_name}_low_ci'] = mid - lo\n",
    "    example[f'{col_name}_hi_ci'] = hi - mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1d5fd-3931-4206-a956-9704eae789ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multi_row_transformation(df, row_transform_fn, col_name, agg_fn):\n",
    "    df[col_name] = df.apply(row_transform_fn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73907c00-ce16-4bce-b6e9-14d9bb68e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _score_rollouts(rollouts):\n",
    "    # rollouts: list/array of rollout sequences; may also be None/np.nan/scalar\n",
    "    if rollouts is None or (isinstance(rollouts, float) and np.isnan(rollouts)):\n",
    "        return np.nan\n",
    "\n",
    "    vals = []\n",
    "    for r in rollouts:\n",
    "        # skip None/NaN\n",
    "        if r is None or (isinstance(r, float) and np.isnan(r)):\n",
    "            continue\n",
    "        vals.append(-np.nansum(r))\n",
    "    return np.nanmean(vals) if len(vals) else np.nan\n",
    "\n",
    "\n",
    "def patch_gpt_api_log_loss(example):\n",
    "    experiment_hash = example['experiment_hash']\n",
    "\n",
    "    translation_loss = os.path.join(root_dir, experiment_hash, \"data\", f\"validation_reverse_translation_math500_meta.json\")\n",
    "    with open(translation_loss, \"r\") as fp:\n",
    "        example[\"backtranslation_gt_logprobs\"] = translation_loss[\"valid_loss\"]\n",
    "\n",
    "    # need to be validation loss on 512k...\n",
    "    validation_loss = os.path.join(root_dir, experiment_hash, \"data\", f\"validation_reverse_translation_math500_meta.json\")\n",
    "    with open(validation_loss, \"r\") as fp:\n",
    "        example[\"backtranslation_gt_logprobs\"] = translation_loss[\"valid_loss\"]\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def process_single_example(example):\n",
    "    experiment_hash = example['experiment_hash']\n",
    "    \n",
    "    target_path = os.path.join(root_dir, example['experiment_hash'], \"data\", \"joined_output.parquet\")\n",
    "    if not os.path.exists(target_path):\n",
    "        print(f\"!!!!!! {target_path} missing !!!!!!!\")\n",
    "        return example\n",
    "    \n",
    "    df_data = pd.read_parquet(target_path)\n",
    "\n",
    "    d_col_to_transform = {\n",
    "        'cot_gt_logprobs' : lambda s: np.nansum(s.map(_score_rollouts)),\n",
    "        'generated_cot_is_correct' : np.mean,  # was np.mean\n",
    "        'backtranslation_gt_logprobs' : lambda s: np.nanmean(s.map(_score_rollouts)),\n",
    "        'backtranslation_bleu_scores' : np.mean,  # was np.mean\n",
    "        'generated_cot_adhered_encoding_style': np.mean  # was np.mean\n",
    "    }\n",
    "    for col, fn in d_col_to_transform.items():\n",
    "        if col not in df_data:\n",
    "            print(col)\n",
    "            print(df_data.head())\n",
    "            print(example)\n",
    "            raise Exception(str(col) + \"\\n\" + str(df_data.head()) + \"\\n\" + str(example))\n",
    "\n",
    "        compute_ci_cols(example, df_data, col, fn)\n",
    "\n",
    "    df_data[\"num_tokens_translation_output\"] = ray.get(compute_translation_token_count.remote(example, df_data))\n",
    "\n",
    "    d_and_cols = {\n",
    "        'adherent_and_correct': (\n",
    "            lambda r: np.nanmean( \\\n",
    "                np.array(r['generated_cot_is_correct']).astype(bool) & \\\n",
    "                np.array(r['generated_cot_adhered_encoding_style']).astype(bool) \\\n",
    "            ),\n",
    "            np.nanmean\n",
    "        ),\n",
    "        'total_translation_loss': (\n",
    "            lambda r: np.nanmean( \\\n",
    "                np.array(r['num_tokens_translation_output']) * \\\n",
    "                np.array(np.nanmean(_score_rollouts(r['backtranslation_gt_logprobs'])), dtype=np.float64) \\\n",
    "            ),\n",
    "            np.nanmean\n",
    "        ),\n",
    "    }\n",
    "    for col, (transform_fn, agg_fn) in d_and_cols.items():\n",
    "        compute_multi_row_transformation(df_data, transform_fn, col, agg_fn)\n",
    "        if df_data[col].isna().sum() != len(df_data):\n",
    "            compute_ci_cols(example, df_data, col, lambda x: x)\n",
    "\n",
    "    if \"gpt\" in example[\"data\"][\"experiment_params\"][\"model\"] and \"use_api_sft_model_for_sampling\" in example[\"data\"][\"experiment_params\"]:\n",
    "        with open(os.path.join(root_dir, example['experiment_hash'], \"data\", f\"validation_reverse_translation_math500_meta.json\"), \"r\") as fp:\n",
    "            d_model_meta = json.load(fp)\n",
    "\n",
    "        example[\"backtranslation_gt_logprobs\"] = d_model_meta[\"valid_loss\"]\n",
    "        example[\"total_translation_loss\"] = d_model_meta[\"valid_loss\"] * np.nanmean(df_data[\"num_tokens_translation_output\"])\n",
    "        example[\"total_translation_loss_low_ci\"] = 0.0\n",
    "        example[\"total_translation_loss_hi_ci\"] = 0.0\n",
    "\n",
    "    pretraining_prevalence_path = os.path.join('/home/ubuntu/sky_workdir/encoding-schemes', 'output', experiment_hash, 'data', 'num_pretraining_4grams_redpajama.json')\n",
    "    if os.path.exists(pretraining_prevalence_path):\n",
    "        with open(pretraining_prevalence_path, \"r\") as fp:\n",
    "            d_pretraining_prevalence = json.load(fp)\n",
    "\n",
    "        example[\"pretraining_prevalence\"] = d_pretraining_prevalence[\"num_occurrences\"]\n",
    "\n",
    "    for col in df_data.columns:\n",
    "        example[f\"{col}_df\"] = df_data[col]\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "l_new_examples = [None for _ in range(len(l_examples))]\n",
    "\n",
    "for i, example in tqdm(enumerate(l_examples)):\n",
    "    # l_examples[i] = process_single_example(example)\n",
    "    l_new_examples[i] = process_single_example.remote(example)\n",
    "\n",
    "for i, example in tqdm(enumerate(l_new_examples)):\n",
    "    try:\n",
    "        l_new_examples[i] = ray.get(example)\n",
    "    except ray.exceptions.RayTaskError as e:\n",
    "        l_new_examples[i] = l_examples[i]\n",
    "        print(e)\n",
    "\n",
    "l_examples = l_new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7b0cc-4d72-4780-9f3a-0fa25ee3a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize_number(num: float) -> str:\n",
    "    \"\"\"\n",
    "    Converts a number into a human-readable string with k, M, or B suffixes.\n",
    "    \n",
    "    Args:\n",
    "        num (float): The number to format.\n",
    "    \n",
    "    Returns:\n",
    "        str: Human-readable string representation.\n",
    "    \"\"\"\n",
    "    if num >= 1_000_000_000:\n",
    "        return f\"{num / 1_000_000_000:.1f}B\"\n",
    "    elif num >= 1_000_000:\n",
    "        return f\"{num / 1_000_000:.1f}M\"\n",
    "    elif num >= 1_000:\n",
    "        return f\"{num / 1_000:.1f}k\"\n",
    "    else:\n",
    "        return str(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c8aa3-b7b1-48a7-b0fc-c8811fe9a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_params(model):\n",
    "    if 'gpt' in model:\n",
    "        if 'nano' in model:\n",
    "            return 0\n",
    "        elif 'mini' in model:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "\n",
    "    if 'claude' in model:\n",
    "        if 'haiku' in model:\n",
    "            return 3\n",
    "        elif 'sonnet' in model:\n",
    "            return 4\n",
    "        else:\n",
    "            return 5\n",
    "    \n",
    "    return int(re.search(\"([0-9]+)B\", model).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a412a1f-de17-4d22-b798-12ea8ce0db67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_viz = pd.DataFrame(l_examples)\n",
    "\n",
    "orig_len = len(df_viz)\n",
    "\n",
    "# df_viz = df_viz[df_viz['cot_gt_logprobs'].notna()]\n",
    "\n",
    "new_len = len(df_viz)\n",
    "if orig_len != new_len:\n",
    "    print(f\"Lost {orig_len - new_len} examples from na logprobs\")\n",
    "\n",
    "df_viz['encoding_scheme'] = df_viz['data'].map(lambda x: x['experiment_params']['encoding_scheme'])\n",
    "df_viz['model'] = df_viz['data'].map(lambda x: x['experiment_params']['model'])\n",
    "\n",
    "try:\n",
    "    df_viz['model_size'] = df_viz['model'].map(parse_params)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "df_viz['input_type'] = df_viz['data'].map(lambda x: \"_\".join(x['experiment_name'].split(\"_\")[:2]))\n",
    "\n",
    "df_viz['n_few_shot_examples'] = df_viz['data'].map(lambda x: x['experiment_params'].get('n_few_shot_examples', None))\n",
    "\n",
    "df_viz['Adherence Calculation Method'] = df_viz['encoding_scheme'].map(lambda x: get_deterministic_adherence_fn(x, None) is not None).map({ True: 'deterministic', False: 'Sonnet 4 judge'})\n",
    "\n",
    "try:\n",
    "    df_viz['total_train_tok'] = df_viz['n_total_train_tok'].map(humanize_number)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d5f60-3ce3-448f-b887-0d0723e8a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_set = ['math_cot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294af9ce-482f-4336-a8bc-6aaf90027383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp = df_viz[df_viz['input_type'].isin(filter_set)]\n",
    "df_viz_tmp = df_viz_tmp[df_viz_tmp['model'] != 'Qwen/Qwen2.5-7B']\n",
    "\n",
    "df_viz_tmp['model'] = df_viz_tmp['model'].str.split('-2025').str[0]\n",
    "df_viz_tmp['model'] = df_viz_tmp['model'].str.split('-latest').str[0]\n",
    "df_viz_tmp['model'] = df_viz_tmp['model'].str.split('Qwen/').str[-1]\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.sort_values([\n",
    "    'model_size',\n",
    "    'adherent_and_correct'\n",
    "])\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.astype({'n_few_shot_examples': str})\n",
    "\n",
    "df_viz_tmp['encoding_scheme'] = df_viz_tmp['encoding_scheme'].map(lambda s: s.split(\"speaking_\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a828d6-6815-4381-b995-20982640f527",
   "metadata": {},
   "source": [
    "# Paper plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea4d31-60d6-443c-8d80-a06febf33739",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mapping = {\n",
    "    \"baseline\": [\"zero_shot\", \"identity\"],\n",
    "    \"letter mutation\": [\n",
    "        \"reverse_letters_in_each_word\",\n",
    "        \"swap_even_odd_letters_in_each_word\",\n",
    "        \"reverse_fibonacci_indices_in_each_word\",\n",
    "        \"letter_to_word_with_dot\",\n",
    "        \"dot_between_chars\",\n",
    "        \"space_between_chars\",\n",
    "    ],\n",
    "    \"language deletion\": [\"remove_all_verbs\", \"remove_all_nouns\"],\n",
    "    \"language translation\": [\n",
    "        \"French\",\"Chinese\",\"Korean\",\"Russian\",\"Arabic\",\"Adyghe\",\n",
    "        \"Morse_code\",\"Python\",\"enterprise_Java\",\n",
    "    ],\n",
    "    \"algorithmic cipher\": [\n",
    "        \"rot13_cipher\",\"base64_cipher\",\"base64_2x_cipher\",\n",
    "        \"base64_3x_cipher\",\"caesar_cipher\",\"gzip_to_base64_encoded\",\n",
    "    ],\n",
    "    \"themed reasoning\": [\n",
    "        \"paraphrase_naive\",\n",
    "        \"pirate_speak\",\n",
    "        \"leet_speak\",\n",
    "        \"yoda_speak\",\n",
    "        \"shakespearean_text\",\n",
    "    ],\n",
    "    \"extraneous content\": [\n",
    "        \"insert_tweet\",\n",
    "        \"python_snippet_comment\",\n",
    "        \"croissant_news_article\",\n",
    "        \"math_textbook_article\",\n",
    "        \"five_emojis\",\n",
    "    ],\n",
    "    \"delete inf.\": [\n",
    "        \"replace_math_content_with_black_box\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "l_themed_encodings = [\n",
    "    \"remove_all_verbs\",\n",
    "    \"paraphrase_naive\",\n",
    "    \"pirate_speak\",\n",
    "    \"leet_speak\",\n",
    "    \"yoda_speak\",\n",
    "    \"shakespearean_text\",\n",
    "    \"insert_tweet\",\n",
    "    \"python_snippet_comment\",\n",
    "    \"croissant_news_article\",\n",
    "    \"math_textbook_article\",\n",
    "    \"five_emojis\",\n",
    "    \"replace_math_content_with_black_box\",\n",
    "    \"reverse_letters_in_each_word_no_math_expressions\",\n",
    "    \"reverse_letters_in_each_word_only_math_expressions\"\n",
    "]\n",
    "\n",
    "l_ignore_languages = [\n",
    "    \"Russian\",\n",
    "    \"Chinese\",\n",
    "    # \"Korean\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b0308-1806-4005-80ec-d83ab4716125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.colors as pc\n",
    "\n",
    "def sample_colorscale(colorscale_name: str, n: int):\n",
    "    \"\"\"\n",
    "    Sample N equally spaced hex colors from a Plotly continuous colorscale.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    colorscale_name : str\n",
    "        Name of a Plotly built-in continuous colorscale (e.g., \"Viridis\", \"Blues\").\n",
    "    n : int\n",
    "        Number of samples to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        List of hex color strings.\n",
    "    \"\"\"\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be >= 1\")\n",
    "    colorscale = px.colors.get_colorscale(colorscale_name)\n",
    "    # equally spaced points in [0,1]\n",
    "    vals = [i/(n-1) if n > 1 else 0.5 for i in range(n)]\n",
    "    return [pc.sample_colorscale(colorscale, v)[0] for v in vals]\n",
    "\n",
    "l_gpt_gradient = sample_colorscale(\"Emrld\", 4 + 1)\n",
    "d_gpt_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['gpt-4.1-nano', 'gpt-4.1-mini', 'gpt-4.1', 'gpt-5-chat'],\n",
    "        l_gpt_gradient[1:]\n",
    "    )\n",
    "}\n",
    "\n",
    "l_claude_gradient = sample_colorscale(\"Magenta\", 3 + 1)\n",
    "d_claude_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['claude-3-opus-20240229', 'claude-3-5-sonnet-20241022', 'claude-sonnet-4-20250514'],\n",
    "        l_claude_gradient[1:]\n",
    "    )\n",
    "}\n",
    "\n",
    "l_qwen_gradient = sample_colorscale(\"Oryel\", 3 + 1)\n",
    "d_qwen_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['Qwen2.5-3B-Instruct', 'Qwen2.5-7B-Instruct', 'Qwen2.5-14B-Instruct'],\n",
    "        l_qwen_gradient[1:]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbea54-0ca9-49b4-a54c-12699bd2d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_star_encodings = [\n",
    "    \"reverse_letters_in_each_word\",\n",
    "    \"rot13_cipher\",\n",
    "    \"caesar_cipher\", # TODO check\n",
    " 'reverse_fibonacci_indices_in_each_word', # TODO check\n",
    " 'swap_even_odd_letters_in_each_word', # TODO check\n",
    "    \"Morse_code\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e2ffbe-0a88-412a-84ba-ef78415e4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_fixed_encoding_ordering = [\n",
    "    # GPT\n",
    "    'identity',\n",
    "    'dot_between_chars',\n",
    "    'Korean',\n",
    "    'letter_to_word_with_dot',\n",
    "    'rot13_cipher',\n",
    "    # 'remove_all_verbs',\n",
    "    'Morse_code',\n",
    "    'base64_cipher',\n",
    "    'reverse_letters_in_each_word',\n",
    "    'reverse_fibonacci_indices_in_each_word',\n",
    "'base64_2x_cipher',\n",
    "\n",
    "\n",
    "    # placeholder for an empty space\n",
    "    '',\n",
    "\n",
    "    # Qwen/Claude\n",
    " 'French',\n",
    " 'space_between_chars',\n",
    " 'Arabic',\n",
    " 'Adyghe',\n",
    " 'caesar_cipher',\n",
    " 'swap_even_odd_letters_in_each_word',\n",
    "    'remove_all_nouns',\n",
    " 'Python',\n",
    "    'enterprise_Java',\n",
    " 'base64_3x_cipher',\n",
    " 'gzip_to_base64_encoded',\n",
    " \n",
    "]\n",
    "\n",
    "# for i in range(len(l_fixed_encoding_ordering)):\n",
    "#     if l_fixed_encoding_ordering[i] in l_star_encodings:\n",
    "#         l_fixed_encoding_ordering[i] += \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28638b7d-2bea-4555-ae24-ccdb98964c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgr[['encoding_scheme', 'model', 'PGR_pct', 'adherent_and_correct', 'generated_cot_is_correct', 'input_type']].to_parquet(\"/home/ubuntu/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c55d5-a543-4d29-8438-7f8edd662956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute PGR (percent of identity performance) ---\n",
    "df_pgr = df_viz_tmp.copy()\n",
    "\n",
    "df_pgr = pd.concat([\n",
    "    df_pgr,\n",
    "    pd.DataFrame([{'encoding_scheme': '', 'model': model} for model in df_pgr['model'].unique()])\n",
    "], ignore_index=True)\n",
    "\n",
    "# Identity baseline per model\n",
    "identity_baseline = (\n",
    "    df_pgr[df_pgr[\"encoding_scheme\"] == \"identity\"]\n",
    "    .set_index(\"model\")[\"adherent_and_correct\"]\n",
    ")\n",
    "\n",
    "df_pgr[\"identity_value\"] = np.maximum(df_pgr[\"model\"].map(identity_baseline), 0.0001)\n",
    "\n",
    "# Avoid divide-by-zero\n",
    "# df_pgr = df_pgr[df_pgr[\"identity_value\"] > 0].copy()\n",
    "\n",
    "# Mean PGR as percentage\n",
    "df_pgr[\"PGR_pct\"] = (df_pgr[\"adherent_and_correct\"] / df_pgr[\"identity_value\"])\n",
    "\n",
    "# CI deltas -> percentage deltas relative to identity baseline\n",
    "# low is negative, high is positive\n",
    "df_pgr[\"PGR_pct_hi_ci\"]  = (df_pgr[\"adherent_and_correct_hi_ci\"] / df_pgr[\"identity_value\"])\n",
    "df_pgr[\"PGR_pct_low_ci\"] = (df_pgr[\"adherent_and_correct_low_ci\"]        / df_pgr[\"identity_value\"])\n",
    "\n",
    "df_pgr.loc[df_pgr[\"encoding_scheme\"] == \"identity\", [\"PGR_pct_hi_ci\", \"PGR_pct_low_ci\"]] = 0.0\n",
    "\n",
    "# order by sonnet 4 hard coded\n",
    "# df_sonnet4 = df_pgr[df_pgr['model'].str.contains('claude-3-5-sonnet')].sort_values('adherent_and_correct', ascending=False)\n",
    "df_sonnet4 = df_pgr[df_pgr['model'].str.contains('14B')].sort_values('adherent_and_correct', ascending=False)\n",
    "# df_sonnet4 = df_pgr[df_pgr['model'].str.contains('sonnet-4')].sort_values('adherent_and_correct', ascending=False)\n",
    "\n",
    "d_encoding_scheme_to_idx = {}\n",
    "for i in range(len(df_sonnet4)):\n",
    "    d_encoding_scheme_to_idx[df_sonnet4['encoding_scheme'].iloc[i]] = i\n",
    "\n",
    "# d_encoding_scheme_to_idx['identity'] = 0\n",
    "\n",
    "for i, encoding in enumerate(l_fixed_encoding_ordering):\n",
    "    d_encoding_scheme_to_idx[encoding] = i\n",
    "\n",
    "df_pgr = df_pgr[~df_pgr['encoding_scheme'].isin(l_themed_encodings)]\n",
    "df_pgr = df_pgr[~df_pgr['encoding_scheme'].isin(l_ignore_languages)]\n",
    "\n",
    "# df_pgr['encoding_scheme'] = df_pgr['encoding_scheme'].map(lambda x: x + '*' if x in l_star_encodings else x)\n",
    "\n",
    "df_pgr['sort_order'] = df_pgr['encoding_scheme'].map(d_encoding_scheme_to_idx)\n",
    "df_pgr = df_pgr.sort_values(['sort_order', 'model_size'])\n",
    "\n",
    "df_pgr['encoding_scheme'] = df_pgr['encoding_scheme'].map(lambda s: \" \".join(s.split('_')))\n",
    "\n",
    "df_pgr['Model Family'] = df_pgr[\"model\"].map(lambda x: \"Qwen2.5\" if \"Qwen2.5\" in x else \"GPT\" if \"gpt\" in x else \"Claude\")\n",
    "\n",
    "fig = px.line(df_pgr[df_pgr['encoding_scheme'] != 'zero shot'],\n",
    "              x='encoding_scheme',\n",
    "              y='PGR_pct',\n",
    "              color='model',\n",
    "              color_discrete_map={**d_claude_gradient, **d_gpt_gradient, **d_qwen_gradient},\n",
    "             # barmode='group'\n",
    "              markers=True,\n",
    "              # facet_col=\"Model Family\"\n",
    ")\n",
    "\n",
    "# s_encoding_scheme_order = df_pgr[df_pgr['model'].str.contains('14B') & (df_pgr['encoding_scheme'] != 'zero shot')]['encoding_scheme']\n",
    "# s_encoding_scheme_order = df_pgr[df_pgr['model'].str.contains('sonnet-4') & (df_pgr['encoding_scheme'] != 'zero shot')]['encoding_scheme']\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        categoryorder=\"array\",\n",
    "        # categoryarray=s_encoding_scheme_order\n",
    "        categoryarray=[' '.join(s.split('_')) for s in l_fixed_encoding_ordering]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=dict(text=title, font=dict(size=22)),\n",
    "    template=\"plotly_white\",\n",
    "    height=530,\n",
    "    width=1800,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.08,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01,\n",
    "        font=dict(size=22)\n",
    "    ),\n",
    "    margin=dict(t=0, r=0, b=0, l=0),\n",
    "    font=dict(size=22),\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title=\"Cipher\")\n",
    "fig.update_yaxes(range=[0.0, 1.05], dtick=0.1, title=\"% of identity adherent & correct\", title_font=dict(size=18), tickfont=dict(size=18))\n",
    "\n",
    "# add the zero shot lines for 4.1 and 14b\n",
    "l_zero_shot_models = ['gpt-4.1']\n",
    "l_cols = [1]\n",
    "l_pos = [\"top right\"]\n",
    "l_model_names = [\"GPT 4.1\"]\n",
    "# l_zero_shot_models = ['gpt-4.1-2025-04-14', \"claude-sonnet-4-20250514\"]\n",
    "# l_cols = [1, 2]\n",
    "\n",
    "for zero_shot_model, col_idx, pos, model_name in zip(l_zero_shot_models, l_cols, l_pos, l_model_names):\n",
    "    zero_shot_perf = df_pgr[(df_pgr['model'] == zero_shot_model) & (df_pgr['encoding_scheme'] == 'zero shot')]['PGR_pct'].iloc[0]\n",
    "\n",
    "    annotation_str = f\"{model_name} direct answering perf.\"\n",
    "    fig.add_hline(y=zero_shot_perf, line_dash='dash', annotation_text=annotation_str, col=col_idx, annotation_position=pos)\n",
    "    # fig.add_hrect(\n",
    "    #     # y0=0.0, y1=zero_shot_perf,\n",
    "    #     y0=zero_shot_perf, y1=1.0,\n",
    "    #     fillcolor=\"#D3D3D3\", opacity=0.2,\n",
    "    #     layer=\"below\", line_width=0,\n",
    "    #     annotation_text=\"Better than GPT 4.1 direct answering\",\n",
    "    #     annotation_font=dict(color=\"grey\")\n",
    "#     )\n",
    "\n",
    "plotly.io.write_image(fig, 'sft_perf.pdf', format='pdf')\n",
    "\n",
    "fig.show('png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f4734-c08e-4ea9-bd9c-9eff85646887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def df_to_latex_table(df_pgr,\n",
    "                      caption=\"Model results\",\n",
    "                      label=\"tab:model-results\",\n",
    "                      percent_decimals=1,\n",
    "                      float_decimals=2):\n",
    "    from io import StringIO\n",
    "\n",
    "    # 1) Build df_export\n",
    "    df_export = df_pgr.copy()\n",
    "    df_export['encoding_scheme'] = df_export['encoding_scheme'].map(\n",
    "        lambda x: 'direct answering' if x == 'zero shot' else x\n",
    "    )\n",
    "\n",
    "    df_export = df_export[\n",
    "        ['model', 'encoding_scheme', 'PGR_pct', 'generated_cot_is_correct',\n",
    "         'generated_cot_adhered_encoding_style', 'backtranslation_bleu_scores',\n",
    "         'Adherence Calculation Method']\n",
    "    ].rename(columns={\n",
    "        'encoding_scheme': 'encoding scheme',\n",
    "        'PGR_pct': '\\\\% of identity adherent + coherent',\n",
    "        'generated_cot_is_correct': 'MATH500 accuracy',\n",
    "        'generated_cot_adhered_encoding_style': 'cipher adherence',\n",
    "        'backtranslation_bleu_scores': 'translation BLEU',\n",
    "    })\n",
    "\n",
    "    # 2) Format numbers\n",
    "    df_fmt = df_export.copy()\n",
    "\n",
    "    col_pct = '\\\\% of identity adherent + coherent'\n",
    "    if pd.api.types.is_numeric_dtype(df_fmt[col_pct]):\n",
    "        s = df_fmt[col_pct].astype(float)\n",
    "        if np.nanmax(s.values) <= 1.5:  # treat as fraction\n",
    "            s = s * 100.0\n",
    "        df_fmt[col_pct] = s.map(lambda x: (f\"{x:.{percent_decimals}f}\\\\%\" if pd.notna(x) else \"\"))\n",
    "\n",
    "    numeric_cols = [\n",
    "        'MATH500 accuracy',\n",
    "        'cipher adherence',\n",
    "        'translation BLEU',\n",
    "    ]\n",
    "    for c in numeric_cols:\n",
    "        if c in df_fmt.columns and pd.api.types.is_numeric_dtype(df_fmt[c]):\n",
    "            df_fmt[c] = df_fmt[c].map(lambda x: (f\"{x:.{float_decimals}f}\" if pd.notna(x) else \"\"))\n",
    "\n",
    "    # 3) Build LaTeX manually with tabularx\n",
    "    buffer = StringIO()\n",
    "    col_names = df_fmt.columns.tolist()\n",
    "\n",
    "    # Choose alignments: first two + last = text (wrap), others numeric\n",
    "    col_spec = \" | \".join([\"p{\" + f\"{0.75 / len(col_names):.2f}\" + \"\\\\linewidth}\" for _ in range(len(col_names))])\n",
    "\n",
    "    # Write header\n",
    "    buffer.write(\"\\\\begin{longtable}[]\")\n",
    "    buffer.write(\"{\" + col_spec + \"}\\n\")\n",
    "\n",
    "    # Column headers\n",
    "    buffer.write(\" & \".join(col_names) + \" \\\\\\\\\\n\")\n",
    "    buffer.write(\"\\\\hline\\n\")\n",
    "\n",
    "    # Rows\n",
    "    for _, row in df_fmt.iterrows():\n",
    "        buffer.write(\" & \".join(str(x) for x in row.tolist()) + \" \\\\\\\\\\n\")\n",
    "\n",
    "    buffer.write(\"\\\\caption{\" + caption + \"}\\n\")\n",
    "    buffer.write(\"\\\\label{\" + label + \"}\\n\")\n",
    "    buffer.write(\"\\\\end{longtable}\\n\")\n",
    "\n",
    "    latex = buffer.getvalue()\n",
    "    print(latex)\n",
    "    return latex\n",
    "\n",
    "\n",
    "\n",
    "df_to_latex_table(df_pgr[df_pgr['PGR_pct'].notna()], caption=\"TODO CAPTION\", label=\"detailed_sft_results_table\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6dcde-fa6a-4f12-8e58-d4d5d162f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_pgr[df_pgr['encoding_scheme'] != 'zero shot'],\n",
    "              x='encoding_scheme',\n",
    "              y='backtranslation_bleu_scores',\n",
    "              color='model',\n",
    "              color_discrete_map={**d_claude_gradient, **d_gpt_gradient, **d_qwen_gradient},\n",
    "             # barmode='group'\n",
    "              markers=True,\n",
    "              # facet_col=\"Model Family\"\n",
    ")\n",
    "\n",
    "# needed for sorting by big model adherent+correct\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        categoryorder=\"array\",\n",
    "        # categoryarray=s_encoding_scheme_order\n",
    "        categoryarray=[' '.join(s.split('_')) for s in l_fixed_encoding_ordering]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=dict(text=title, font=dict(size=22)),\n",
    "    template=\"plotly_white\",\n",
    "    height=500,\n",
    "    width=1800,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.08,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01,\n",
    "        font=dict(size=22)\n",
    "    ),\n",
    "    margin=dict(t=0, r=0, b=0, l=0),\n",
    "    font=dict(size=22),\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title=\"Cipher\")\n",
    "fig.update_yaxes(range=[0, 101], dtick=20, title=\"BLEU score\")\n",
    "\n",
    "fig.add_hrect(\n",
    "    y0=50, y1=100,\n",
    "    fillcolor=\"#D3D3D3\", opacity=0.25,\n",
    "    layer=\"below\", line_width=0,\n",
    "    annotation_text=\"Fluent decoding\",\n",
    "    annotation_font=dict(color=\"grey\")\n",
    ")\n",
    "\n",
    "# fig.update_layout(width=600, height=600, title=None)\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_layout(height=600)\n",
    "\n",
    "plotly.io.write_image(fig, 'sft_translation_perf.pdf', format='pdf')\n",
    "\n",
    "fig.show('png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3201600-71d9-456e-ab1e-b129a137a1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_zero_shot_decode = pd.read_parquet(\"zero_shot_decode_data.parquet\")\n",
    "\n",
    "df_zero_shot_decode['model'] = df_zero_shot_decode['model'].str.split('-2025').str[0]\n",
    "\n",
    "df_zero_shot_decode[['encoding_scheme', 'model']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56afd72-6190-497a-b05b-fd0f55019eb0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from scipy.optimize import curve_fit\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "# from scipy.optimize import curve_fit\n",
    "\n",
    "# def styled_logistic_scatter_faceted(\n",
    "#     df,\n",
    "#     facet_col=\"model\",\n",
    "#     x_col=\"backtranslation_gt_logprobs\",\n",
    "#     y_col=\"adherent_and_correct\",\n",
    "#     title=\"Adherence vs. Backtranslation Log-Prob\",\n",
    "#     x_axis_title=\"Backtranslation log-prob\",\n",
    "#     y_axis_title=\"Adherent & correct\",\n",
    "#     font_family=\"Inter, Arial\",\n",
    "#     marker_size=7,\n",
    "#     opacity=0.6,\n",
    "#     legend_font_size=10,\n",
    "#     x_tick_font_size=10,\n",
    "#     line_width=3,\n",
    "#     r2_digits=3,               # <— precision for R² display\n",
    "#     keep_subplot_title=True,\n",
    "#     max_pow_override=None\n",
    "# ):\n",
    "#     def logistic(x, L, k, x0):\n",
    "#         return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "#     # overall y-scale to decide percent formatting\n",
    "#     y_all = df[y_col].to_numpy(dtype=float)\n",
    "#     is_percent = (np.nanmin(y_all) >= 0) and (np.nanmax(y_all) <= 1.0)\n",
    "\n",
    "#     # facet ordering\n",
    "#     if pd.api.types.is_categorical_dtype(df[facet_col]):\n",
    "#         facet_values = [c for c in df[facet_col].cat.categories if (df[df[facet_col]==c].shape[0] > 0)]\n",
    "#     else:\n",
    "#         d_model_to_size = dict(zip(df['model'], df['model_size']))\n",
    "#         facet_values = sorted(df[facet_col].dropna().unique(), key=lambda x: d_model_to_size.get(x, x))\n",
    "\n",
    "#     print(facet_values)\n",
    "\n",
    "#     n_cols = max(1, len(facet_values))\n",
    "#     fig = make_subplots(\n",
    "#         rows=1, cols=n_cols, shared_yaxes=True, horizontal_spacing=0.06,\n",
    "#         subplot_titles=[f\"{facet_col} = {v}\" if keep_subplot_title else None for v in facet_values],\n",
    "#     )\n",
    "\n",
    "#     x_positive = df[df[x_col] > 0][x_col]\n",
    "#     min_x, max_x = x_positive.min(), x_positive.max()\n",
    "#     # Create tick values at decade intervals\n",
    "#     min_pow = int(np.floor(np.log2(min_x)))\n",
    "#     max_pow = int(np.ceil(np.log2(max_x)))\n",
    "#     tick_vals = [2 ** p for p in range(min_pow, max_pow + 1)]\n",
    "#     if max_pow_override:\n",
    "#         if tick_vals[-1] > max_pow_override:\n",
    "#             tick_vals[-1] = max_pow_override\n",
    "#     tick_text = [f\"{v:g}\" for v in tick_vals]\n",
    "\n",
    "#     for i, val in enumerate(facet_values, start=1):\n",
    "#         sub = df[df[facet_col] == val]\n",
    "#         x = sub[x_col].to_numpy(dtype=float)\n",
    "#         y = sub[y_col].to_numpy(dtype=float)\n",
    "\n",
    "#         # points\n",
    "#         fig.add_trace(\n",
    "#             go.Scatter(\n",
    "#                 x=x, y=y, mode=\"markers+text\", name=f\"Points ({val})\",\n",
    "#                 marker=dict(size=marker_size, line=dict(width=0)),\n",
    "#                 opacity=opacity, showlegend=False,\n",
    "#                 text=sub[\"encoding_scheme\"] + \"-\" + sub[\"model\"],\n",
    "#                 hovertemplate=\"<b>%{text}</b><extra></extra>\",  # <-- Just encoding scheme\n",
    "#             ),\n",
    "#             row=1, col=i\n",
    "#         )\n",
    "\n",
    "#         # choose regressor space\n",
    "#         # linear_on_log_x = True\n",
    "#         # if linear_on_log_x:\n",
    "#         #     valid = (x > 0) & np.isfinite(x) & np.isfinite(y)\n",
    "#         #     X = np.log2(x[valid])\n",
    "#         #     Y = y[valid]\n",
    "#         # else:\n",
    "#         #     valid = np.isfinite(x) & np.isfinite(y)\n",
    "#         #     X = x[valid]\n",
    "#         #     Y = y[valid]\n",
    "\n",
    "#         # if X.size >= 2 and np.nanstd(Y) > 0:\n",
    "#         #     b1, b0 = np.polyfit(X, Y, 1)   # Y = b1*X + b0\n",
    "#         #     # make a smooth line across current x-range\n",
    "#         #     x_line = np.linspace(np.nanmin(x[valid]), np.nanmax(x[valid]), 300)\n",
    "#         #     X_line = np.log2(x_line) if linear_on_log_x else x_line\n",
    "#         #     y_line = b1 * X_line + b0\n",
    "\n",
    "#         #     # R^2 on observed points (in same space used to fit)\n",
    "#         #     y_hat = b1 * X + b0\n",
    "#         #     ss_res = np.nansum((Y - y_hat) ** 2)\n",
    "#         #     ss_tot = np.nansum((Y - np.nanmean(Y)) ** 2)\n",
    "#         #     if ss_tot > 0 and np.isfinite(ss_res):\n",
    "#         #         r2 = 1 - ss_res / ss_tot\n",
    "#         #         r2_text = f\"{r2:.{r2_digits}f}\"\n",
    "\n",
    "#         #     fig.add_trace(\n",
    "#         #         go.Scatter(\n",
    "#         #             x=x_line, y=y_line, mode=\"lines\",\n",
    "#         #             name=f\"Linear fit ({val})\",\n",
    "#         #             # line=linear_line_kwargs,\n",
    "#         #             showlegend=(i == 1),\n",
    "#         #         ),\n",
    "#         #         row=1, col=i\n",
    "#         #     )\n",
    "        \n",
    "#         # logistic fit + R^2\n",
    "#         r2_text = \"—\"\n",
    "#         try:\n",
    "#             if np.isfinite(x).sum() >= 3 and np.nanstd(y) > 0:\n",
    "#                 p0 = [np.nanmax(y), 1.0, np.nanmedian(x)]\n",
    "#                 params, _ = curve_fit(logistic, x, y, p0=p0, maxfev=10000)\n",
    "#                 L, k, x0 = params\n",
    "\n",
    "#                 x_fit = np.linspace(np.nanmin(x), max(np.nanmax(x), 98), 300)\n",
    "#                 y_fit = logistic(x_fit, L, k, x0)\n",
    "\n",
    "#                 # R^2 on observed x\n",
    "#                 y_hat = logistic(x, L, k, x0)\n",
    "#                 ss_res = np.nansum((y - y_hat) ** 2)\n",
    "#                 ss_tot = np.nansum((y - np.nanmean(y)) ** 2)\n",
    "#                 if ss_tot > 0 and np.isfinite(ss_res):\n",
    "#                     r2 = 1 - ss_res / ss_tot\n",
    "#                     r2_text = f\"{r2:.{r2_digits}f}\"\n",
    "\n",
    "#                 # fig.add_trace(\n",
    "#                 #     go.Scatter(\n",
    "#                 #         x=x_fit, y=y_fit, mode=\"lines\",\n",
    "#                 #         name=f\"Logistic fit ({val})\",\n",
    "#                 #         line=dict(width=1, color=\"black\", dash=\"dash\"),\n",
    "#                 #         showlegend=(i == 1),\n",
    "#                 #     ),\n",
    "#                 #     row=1, col=i\n",
    "#                 # )\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             pass\n",
    "\n",
    "#         # R^2 annotation (top-left of this subplot)\n",
    "#         # fig.add_annotation(\n",
    "#         #     x=0.1, y=0.05,\n",
    "#         #     xref=f\"x{i}\" if i > 1 else \"x\",   # ✅ Use proper axis names\n",
    "#         #     yref=f\"y{i}\" if i > 1 else \"y\",\n",
    "#         #     xanchor=\"left\",\n",
    "#         #     yanchor=\"bottom\",\n",
    "#         #     text=f\"R² = {r2_text}\",\n",
    "#         #     showarrow=False,\n",
    "#         #     font=dict(size=12),\n",
    "#         #     align=\"left\",\n",
    "#         #     bgcolor=\"rgba(255,255,255,0.6)\",\n",
    "#         #     bordercolor=\"rgba(0,0,0,0.2)\",\n",
    "#         #     borderwidth=1,\n",
    "#         # )\n",
    "\n",
    "#         # axes cosmetics\n",
    "#         fig.update_xaxes(\n",
    "#             title=x_axis_title if i == 1 else \"\",\n",
    "#             tickfont=dict(size=x_tick_font_size),\n",
    "#             zeroline=False,\n",
    "#             # type=\"log\",\n",
    "#             # autorange=\"reversed\",\n",
    "#             # tickvals=tick_vals,\n",
    "#             # ticktext=tick_text,\n",
    "#             row=1, col=i,\n",
    "#             # dtick=0.1\n",
    "#         )\n",
    "#         fig.update_yaxes(\n",
    "#             tickformat=\".0%\" if is_percent else \",\",\n",
    "#             rangemode=\"tozero\",\n",
    "#             zeroline=False,\n",
    "#             dtick=0.05,\n",
    "#             row=1, col=i,\n",
    "#             title=y_axis_title\n",
    "#         )\n",
    "\n",
    "#     fig.update_layout(\n",
    "#         template=\"plotly_white\",\n",
    "#         title=dict(text=title, font=dict(size=18)),\n",
    "#         height=600,\n",
    "#         width=350 * n_cols if n_cols <= 3 else 300 * n_cols,\n",
    "#         font=dict(family=font_family, size=15),\n",
    "#         margin=dict(t=0, r=0, b=0, l=0),\n",
    "#         legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.08, xanchor=\"left\", x=0,\n",
    "#                     font=dict(size=legend_font_size)),\n",
    "#         showlegend=False\n",
    "#     )\n",
    "#     # global axis labels\n",
    "#     # fig.add_annotation(text=x_axis_title, showarrow=False, xref=\"paper\", yref=\"paper\",\n",
    "#     #                    x=0.5, y=-0.18, font=dict(size=14))\n",
    "#     # fig.add_annotation(text=y_axis_title, showarrow=False, xref=\"paper\", yref=\"paper\",\n",
    "#     #                    x=-0.06, y=0.5, textangle=-90, font=dict(size=14))\n",
    "\n",
    "#     return fig\n",
    "\n",
    "\n",
    "# # ---- Use it on your dataframe ----\n",
    "# df_viz_tmp_plot = df_viz_tmp.copy()\n",
    "\n",
    "# df_viz_tmp_plot['encoding_scheme'] = df_viz_tmp_plot['encoding_scheme'].str.split('speaking_').str[-1]\n",
    "# df_viz_tmp_plot['encoding_scheme'] = df_viz_tmp_plot['encoding_scheme'].str.replace(\"_\", \" \")\n",
    "\n",
    "# df_zero_shot_decode['one_step_down_model'] = df_zero_shot_decode['model'].map({\n",
    "#     'gpt-4.1-nano': 'gpt-4.1-mini',\n",
    "#     'gpt-4.1-mini': 'gpt-4.1'\n",
    "# })\n",
    "\n",
    "# df_viz_tmp_plot = df_viz_tmp_plot.merge(df_zero_shot_decode, left_on=['model', 'encoding_scheme'], right_on=['one_step_down_model', 'encoding_scheme'], how='left', suffixes=('', '_zero_shot'))\n",
    "\n",
    "# df_viz_tmp_plot[\"placeholder_col\"] = \"1\"\n",
    "\n",
    "# identity_baseline = (\n",
    "#     df_viz_tmp_plot[df_viz_tmp_plot[\"encoding_scheme\"] == \"identity\"]\n",
    "#     .set_index(\"model\")[\"adherent_and_correct\"]\n",
    "# )\n",
    "\n",
    "# df_viz_tmp_plot[\"identity_value\"] = np.maximum(df_viz_tmp_plot[\"model\"].map(identity_baseline), 0.0001)\n",
    "\n",
    "# # Avoid divide-by-zero\n",
    "# # df_pgr = df_pgr[df_pgr[\"identity_value\"] > 0].copy()\n",
    "\n",
    "# # Mean PGR as percentage\n",
    "# df_viz_tmp_plot[\"PGR_pct\"] = (df_viz_tmp_plot[\"adherent_and_correct\"] / df_viz_tmp_plot[\"identity_value\"])\n",
    "\n",
    "# df_viz_tmp_plot = df_viz_tmp_plot[~df_viz_tmp_plot['encoding_scheme'].isin(['identity', 'zero shot'])]\n",
    "\n",
    "# # df_viz_tmp_plot = df_viz_tmp_plot[~df_viz_tmp_plot['model'].str.contains('mini')]\n",
    "# # df_viz_tmp_plot = df_viz_tmp_plot[~df_viz_tmp_plot['model'].str.contains('nano')]\n",
    "\n",
    "\n",
    "# fig = styled_logistic_scatter_faceted(\n",
    "#     # df_viz_tmp_plot[df_viz_tmp_plot['backtranslation_bleu_scores'].notna() & ~df_viz_tmp_plot['model'].str.contains('gpt')],\n",
    "#     #[df_viz_tmp_plot['adherent_and_correct'] > 0.01],\n",
    "#     df_viz_tmp_plot,\n",
    "#     # df_viz_tmp_plot[(df_viz_tmp_plot['adherent_and_correct'] >= df_viz_tmp_plot['model'].map(d_zero_shot_baseline))],\n",
    "#     # x_col=\"backtranslation_gt_logprobs\",\n",
    "#     x_col=\"backtranslation_bleu_scores_zero_shot\",\n",
    "#     # y_col=\"adherent_and_correct\",\n",
    "#     y_col=\"PGR_pct\",\n",
    "#     # y_col='cot_gt_logprobs',\n",
    "#     # title=\"% of responses adherent & correct vs. encoded -> English translation BLEU\",\n",
    "#     title=None,\n",
    "#     x_axis_title=\"BLEU score\",\n",
    "#     # x_axis_title=\"Encoded text to English text log loss\",\n",
    "#     y_axis_title=\"% of identity adherent & correct\",\n",
    "#     # facet_col=\"model\",\n",
    "#     facet_col=\"placeholder_col\",\n",
    "#     keep_subplot_title=False,\n",
    "#     max_pow_override=100,\n",
    "#     x_tick_font_size=15\n",
    "# )\n",
    "\n",
    "\n",
    "# fig.update_layout(width=600, height=500, title=None)\n",
    "# # fig.update_layout(width=1600, height=1200, title=None)\n",
    "# # --- shaded region instead of vline ---\n",
    "# x_cut = 60\n",
    "# x_right = float(df_viz_tmp_plot[\"backtranslation_bleu_scores\"].max()) + 5\n",
    "# # x_cut = 0.2\n",
    "# # x_right = 0.02\n",
    "\n",
    "\n",
    "# # fig.add_vrect(\n",
    "# #     x0=x_cut, x1=x_right,           # shade from cutoff to the right edge of data\n",
    "# #     fillcolor=\"#D3D3D3\", opacity=0.25,\n",
    "# #     line_width=0,\n",
    "# #     layer=\"below\",\n",
    "# #     row=1, col=1                    # adjust if you facet into multiple columns\n",
    "# # )\n",
    "\n",
    "# # # label for the shaded region\n",
    "# # fig.add_annotation(\n",
    "# #     x=0.99,\n",
    "# #     # x=0.85,\n",
    "# #     xref=\"paper\",           # data coordinates\n",
    "# #     y=0.99, yref=\"paper\",\n",
    "# #     text=\"Fluent<br>decoding\",\n",
    "# #     showarrow=False,\n",
    "# #     xanchor=\"right\",\n",
    "# #     align=\"right\",\n",
    "# #     yanchor=\"top\",\n",
    "# #     bgcolor=\"rgba(255,255,255,0.0)\",\n",
    "# #     bordercolor=\"rgba(0,0,0,0.0)\",\n",
    "# #     borderwidth=0,\n",
    "# #     font=dict(size=14)\n",
    "# # )\n",
    "# fig.update_traces(textposition=\"bottom center\", opacity=0.8)\n",
    "# fig.update_layout(font=dict(size=15))\n",
    "\n",
    "# fig.update_yaxes(range=[-0.04, 1.0])\n",
    "# fig.update_xaxes(range=[0, 100])\n",
    "\n",
    "# fig.show()\n",
    "# # fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fac96b-eb6f-4039-952e-716dea87e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "SELECT MIN(PGR_pct), MAX(PGR_pct), MIN(generated_cot_is_correct), MAX(generated_cot_is_correct) FROM df_pgr\n",
    "WHERE -- model LIKE '%gpt-4.1-2025%' AND\n",
    "encoding_scheme NOT LIKE '%identity%'\n",
    "AND backtranslation_bleu_scores > 95\n",
    "-- AND generated_cot_is_correct > 0.05\n",
    "\"\"\").to_df().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dfcf1f-2aae-4afc-83a3-bff7cbd92a6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "SELECT * FROM df_pgr\n",
    "WHERE \n",
    "model LIKE '%gpt-4.1%' AND\n",
    "encoding_scheme LIKE '%fibonacci%'\n",
    "\"\"\").to_df().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4240aa-e971-4e50-88cb-0dbeed0b9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp[(df_viz_tmp['encoding_scheme'] == 'base64_cipher') & (df_viz_tmp['model'].str.contains('4.1'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767bbcc7-1c40-495c-9b4d-23d4aa035048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/home/ubuntu/sky_workdir/encoding-schemes/output/7b88a15cc7e51bd9ce792e47c494d2530577f989/data/joined_output.parquet\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c5bd30-07e6-4f16-8076-3054d2946eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd8bb3-d401-4883-918b-0693bfdd653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['reference_problem'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a6740-a9cf-422a-95f5-8dae7f1bd6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['translated_solution'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416d2a9-9230-4751-9163-53963d654b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['reference_solution'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70744393-9551-4544-ba67-2dca6a1d9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['generated_backtranslations'].iloc[idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125cf531-cd7a-4c32-be0d-ca0b1def2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['backtranslation_bleu_scores'].iloc[idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6905196c-d27f-48c0-9c99-344ad2f3def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['generated_cots'].iloc[idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c576f-e63f-4203-b162-8380b62b9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generated_cot_is_correct'].iloc[idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef9778-79a9-4f3e-8686-f50cacf0345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoding_schemes.ciphers import inverse_base64_cipher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded55674-8c24-418b-b0d3-57a1fadf1954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import codecs\n",
    "\n",
    "# print(codecs.decode(df['generated_cots'].iloc[idx][2], 'rot13'))\n",
    "\n",
    "import base64\n",
    "\n",
    "print(inverse_base64_cipher(df['generated_cots'].iloc[idx][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b9b937-7a5d-4555-af4d-5e6a90b92f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
