{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d0a44-0aae-4a22-9ea2-552f1efd9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31791de-bdbf-44f4-ac17-de4f754d0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/sky_workdir/encoding-schemes\")\n",
    "\n",
    "from encoding_schemes import get_deterministic_adherence_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8432f-7bb7-4bb8-8223-ea329456a590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8ad9e-91d3-4e3b-b25c-9f19f3e4b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "conn_string = os.environ[\"SUPABASE_CONNECTION_URL\"]\n",
    "\n",
    "conn = psycopg2.connect(conn_string)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b3a2c-ade1-42ca-a798-5b94232485d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_str = \"\"\"\n",
    "-- prompted no sft decode\n",
    "(\n",
    "    (data->'experiment_tags'->'numina_math_cot_rerun')::BOOL\n",
    "    AND (NOT (data->'force_overwrite')::BOOL OR data->'force_overwrite' IS NULL)\n",
    "    AND (data->'experiment_name')::TEXT LIKE '%prompteddecode%'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(f\"\"\"\n",
    "SELECT * FROM public.encoding_schemes \n",
    "    WHERE \n",
    "\n",
    "{sel_str}\n",
    "\n",
    "\n",
    "ORDER BY created_at DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439f59a-7755-482d-ac55-c324ac5bed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/ubuntu/sky_workdir/encoding-schemes/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d72f27-7ec8-4ffd-b530-f2b0b27cefab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_examples = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef482ac-2bcb-46ad-81d0-1a2e523a92e7",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a81ec-f561-430e-8570-c9d4a2a0f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap_ci(data, statistic=np.mean, alpha=0.05, n_boot=10_000, random_state=None):\n",
    "    \"\"\"\n",
    "    Returns (point_estimate, low_CI, high_CI) for given 1D data.\n",
    "    Works with bool, int, or float data.\n",
    "    \"\"\"\n",
    "    x = np.asarray(data).astype(float)  # ensure numeric\n",
    "    x = x[~np.isnan(x)]\n",
    "    if len(x) == 0:\n",
    "        raise ValueError(\"No valid data for bootstrapping.\")\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(x)\n",
    "\n",
    "    # Draw bootstrap samples\n",
    "    idx = rng.integers(0, n, size=(n_boot, n))\n",
    "    samples = x[idx]\n",
    "\n",
    "    # Apply statistic row-wise\n",
    "    stats = np.apply_along_axis(statistic, 1, samples)\n",
    "\n",
    "    point = statistic(x)\n",
    "    lo = np.percentile(stats, 100 * (alpha / 2))\n",
    "    hi = np.percentile(stats, 100 * (1 - alpha / 2))\n",
    "    return point, lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fb9f9-33d1-4e61-b837-cc8b37219291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def count_tokens_from_messages(s):\n",
    "    try:\n",
    "        return len(encoding.encode(s, disallowed_special=()))\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db9fcc-ffa9-4a77-ad34-88067f4d63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=2, memory=32 * 1024 * 1024 * 1024)\n",
    "def compute_translation_token_count(example, df_data):\n",
    "    sys.path.append(\"/home/ubuntu/sky_workdir/encoding-schemes\")\n",
    "\n",
    "    from orchestration.experiment_meta_saver import compute_experiment_hash\n",
    "    from utils.io_utils import read_large_parquet\n",
    "\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    model = example[\"data\"][\"experiment_params\"][\"model\"]\n",
    "    if \"gpt\" in model or \"claude\" in model:\n",
    "        print(f\"Overriding tokenizer for {model} with gpt-oss 120b tokenizer because it was detected as a GPT/Claude model!\")\n",
    "        model = \"openai/gpt-oss-120b\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "    return df_data['reference_solution'].map(lambda x: len(tokenizer.encode(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f84e71-0f86-4e06-b744-96e3e6a71ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231976a-7a7d-4f2a-90f8-eaa70083c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ci_cols(example, df, col_name, transformation_fn):\n",
    "    s_transformed = transformation_fn(df[col_name])\n",
    "    if np.isscalar(s_transformed) and np.isnan(s_transformed):\n",
    "        print(f\"Warning: {col_name} was all NaN, ignoring!\")\n",
    "        return\n",
    "    mid, lo, hi = bootstrap_ci(s_transformed)\n",
    "    example[col_name] = mid\n",
    "    example[f'{col_name}_low_ci'] = mid - lo\n",
    "    example[f'{col_name}_hi_ci'] = hi - mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1d5fd-3931-4206-a956-9704eae789ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multi_row_transformation(df, row_transform_fn, col_name, agg_fn):\n",
    "    df[col_name] = df.apply(row_transform_fn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73907c00-ce16-4bce-b6e9-14d9bb68e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _score_rollouts(rollouts):\n",
    "    # rollouts: list/array of rollout sequences; may also be None/np.nan/scalar\n",
    "    if rollouts is None or (isinstance(rollouts, float) and np.isnan(rollouts)):\n",
    "        return np.nan\n",
    "\n",
    "    vals = []\n",
    "    for r in rollouts:\n",
    "        # skip None/NaN\n",
    "        if r is None or (isinstance(r, float) and np.isnan(r)):\n",
    "            continue\n",
    "        vals.append(-np.nansum(r))\n",
    "    return np.nanmean(vals) if len(vals) else np.nan\n",
    "\n",
    "\n",
    "def patch_gpt_api_log_loss(example):\n",
    "    experiment_hash = example['experiment_hash']\n",
    "\n",
    "    translation_loss = os.path.join(root_dir, experiment_hash, \"data\", f\"validation_reverse_translation_math500_meta.json\")\n",
    "    with open(translation_loss, \"r\") as fp:\n",
    "        example[\"backtranslation_gt_logprobs\"] = translation_loss[\"valid_loss\"]\n",
    "\n",
    "    # need to be validation loss on 512k...\n",
    "    validation_loss = os.path.join(root_dir, experiment_hash, \"data\", f\"validation_reverse_translation_math500_meta.json\")\n",
    "    with open(validation_loss, \"r\") as fp:\n",
    "        example[\"backtranslation_gt_logprobs\"] = translation_loss[\"valid_loss\"]\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def process_single_example(example):\n",
    "    experiment_hash = example['experiment_hash']\n",
    "    \n",
    "    target_path = os.path.join(root_dir, example['experiment_hash'], \"data\", \"joined_output.parquet\")\n",
    "    if not os.path.exists(target_path):\n",
    "        print(f\"!!!!!! {target_path} missing !!!!!!!\")\n",
    "        return example\n",
    "    \n",
    "    df_data = pd.read_parquet(target_path)\n",
    "\n",
    "    d_col_to_transform = {\n",
    "        'cot_gt_logprobs' : lambda s: np.nansum(s.map(_score_rollouts)),\n",
    "        'generated_cot_is_correct' : np.mean,  # was np.mean\n",
    "        'backtranslation_gt_logprobs' : lambda s: np.nanmean(s.map(_score_rollouts)),\n",
    "        'backtranslation_bleu_scores' : np.mean,  # was np.mean\n",
    "        'generated_cot_adhered_encoding_style': np.mean  # was np.mean\n",
    "    }\n",
    "    for col, fn in d_col_to_transform.items():\n",
    "        if col not in df_data:\n",
    "            print(col)\n",
    "            print(df_data.head())\n",
    "            print(example)\n",
    "            raise Exception(str(col) + \"\\n\" + str(df_data.head()) + \"\\n\" + str(example))\n",
    "\n",
    "        compute_ci_cols(example, df_data, col, fn)\n",
    "\n",
    "    df_data[\"num_tokens_translation_output\"] = ray.get(compute_translation_token_count.remote(example, df_data))\n",
    "\n",
    "    d_and_cols = {\n",
    "        'adherent_and_correct': (\n",
    "            lambda r: np.nanmean( \\\n",
    "                np.array(r['generated_cot_is_correct']).astype(bool) & \\\n",
    "                np.array(r['generated_cot_adhered_encoding_style']).astype(bool) \\\n",
    "            ),\n",
    "            np.nanmean\n",
    "        ),\n",
    "        'total_translation_loss': (\n",
    "            lambda r: np.nanmean( \\\n",
    "                np.array(r['num_tokens_translation_output']) * \\\n",
    "                np.array(np.nanmean(_score_rollouts(r['backtranslation_gt_logprobs'])), dtype=np.float64) \\\n",
    "            ),\n",
    "            np.nanmean\n",
    "        ),\n",
    "    }\n",
    "    for col, (transform_fn, agg_fn) in d_and_cols.items():\n",
    "        compute_multi_row_transformation(df_data, transform_fn, col, agg_fn)\n",
    "        if df_data[col].isna().sum() != len(df_data):\n",
    "            compute_ci_cols(example, df_data, col, lambda x: x)\n",
    "\n",
    "    if \"gpt\" in example[\"data\"][\"experiment_params\"][\"model\"] and \"use_api_sft_model_for_sampling\" in example[\"data\"][\"experiment_params\"]:\n",
    "        with open(os.path.join(root_dir, example['experiment_hash'], \"data\", f\"validation_reverse_translation_math500_meta.json\"), \"r\") as fp:\n",
    "            d_model_meta = json.load(fp)\n",
    "\n",
    "        example[\"backtranslation_gt_logprobs\"] = d_model_meta[\"valid_loss\"]\n",
    "        example[\"total_translation_loss\"] = d_model_meta[\"valid_loss\"] * np.nanmean(df_data[\"num_tokens_translation_output\"])\n",
    "        example[\"total_translation_loss_low_ci\"] = 0.0\n",
    "        example[\"total_translation_loss_hi_ci\"] = 0.0\n",
    "\n",
    "    pretraining_prevalence_path = os.path.join('/home/ubuntu/sky_workdir/encoding-schemes', 'output', experiment_hash, 'data', 'num_pretraining_4grams_redpajama.json')\n",
    "    if os.path.exists(pretraining_prevalence_path):\n",
    "        with open(pretraining_prevalence_path, \"r\") as fp:\n",
    "            d_pretraining_prevalence = json.load(fp)\n",
    "\n",
    "        example[\"pretraining_prevalence\"] = d_pretraining_prevalence[\"num_occurrences\"]\n",
    "\n",
    "    for col in df_data.columns:\n",
    "        example[f\"{col}_df\"] = df_data[col]\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "l_new_examples = [None for _ in range(len(l_examples))]\n",
    "\n",
    "for i, example in tqdm(enumerate(l_examples)):\n",
    "    # l_examples[i] = process_single_example(example)\n",
    "    l_new_examples[i] = process_single_example.remote(example)\n",
    "\n",
    "for i, example in tqdm(enumerate(l_new_examples)):\n",
    "    try:\n",
    "        l_new_examples[i] = ray.get(example)\n",
    "    except ray.exceptions.RayTaskError as e:\n",
    "        l_new_examples[i] = l_examples[i]\n",
    "        print(e)\n",
    "\n",
    "l_examples = l_new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7b0cc-4d72-4780-9f3a-0fa25ee3a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize_number(num: float) -> str:\n",
    "    \"\"\"\n",
    "    Converts a number into a human-readable string with k, M, or B suffixes.\n",
    "    \n",
    "    Args:\n",
    "        num (float): The number to format.\n",
    "    \n",
    "    Returns:\n",
    "        str: Human-readable string representation.\n",
    "    \"\"\"\n",
    "    if num >= 1_000_000_000:\n",
    "        return f\"{num / 1_000_000_000:.1f}B\"\n",
    "    elif num >= 1_000_000:\n",
    "        return f\"{num / 1_000_000:.1f}M\"\n",
    "    elif num >= 1_000:\n",
    "        return f\"{num / 1_000:.1f}k\"\n",
    "    else:\n",
    "        return str(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c8aa3-b7b1-48a7-b0fc-c8811fe9a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_params(model):\n",
    "    if 'gpt' in model:\n",
    "        if 'nano' in model:\n",
    "            return 0\n",
    "        elif 'mini' in model:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "\n",
    "    if 'claude' in model:\n",
    "        if 'haiku' in model:\n",
    "            return 3\n",
    "        elif '3-opus' in model:\n",
    "            return 4\n",
    "        elif '3-5' in model:\n",
    "            return 5\n",
    "        elif 'sonnet-4' in model:\n",
    "            return 6\n",
    "        else:\n",
    "            return 7\n",
    "    \n",
    "    return int(re.search(\"([0-9]+)B\", model).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a412a1f-de17-4d22-b798-12ea8ce0db67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_viz = pd.DataFrame(l_examples)\n",
    "\n",
    "orig_len = len(df_viz)\n",
    "\n",
    "# df_viz = df_viz[df_viz['cot_gt_logprobs'].notna()]\n",
    "\n",
    "new_len = len(df_viz)\n",
    "if orig_len != new_len:\n",
    "    print(f\"Lost {orig_len - new_len} examples from na logprobs\")\n",
    "\n",
    "df_viz['encoding_scheme'] = df_viz['data'].map(lambda x: x['experiment_params']['encoding_scheme'])\n",
    "df_viz['model'] = df_viz['data'].map(lambda x: x['experiment_params']['model'])\n",
    "\n",
    "try:\n",
    "    df_viz['model_size'] = df_viz['model'].map(parse_params)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "df_viz['input_type'] = df_viz['data'].map(lambda x: \"_\".join(x['experiment_name'].split(\"_\")[:2]))\n",
    "\n",
    "df_viz['n_few_shot_examples'] = df_viz['data'].map(lambda x: x['experiment_params'].get('n_few_shot_examples', None))\n",
    "\n",
    "df_viz['Adherence Calculation Method'] = df_viz['encoding_scheme'].map(lambda x: get_deterministic_adherence_fn(x, None) is not None).map({ True: 'deterministic', False: 'Sonnet 4 judge'})\n",
    "\n",
    "try:\n",
    "    df_viz['total_train_tok'] = df_viz['n_total_train_tok'].map(humanize_number)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d5f60-3ce3-448f-b887-0d0723e8a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_set = ['mathcot_prompteddecode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294af9ce-482f-4336-a8bc-6aaf90027383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp = df_viz[df_viz['input_type'].isin(filter_set)]\n",
    "df_viz_tmp = df_viz_tmp[df_viz_tmp['model'] != 'Qwen/Qwen2.5-7B']\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.sort_values([\n",
    "    'model_size',\n",
    "    'adherent_and_correct'\n",
    "])\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.astype({'n_few_shot_examples': str})\n",
    "\n",
    "df_viz_tmp['encoding_scheme'] = df_viz_tmp['encoding_scheme'].map(lambda s: s.split(\"speaking_\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a828d6-6815-4381-b995-20982640f527",
   "metadata": {},
   "source": [
    "# Paper plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea4d31-60d6-443c-8d80-a06febf33739",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mapping = {\n",
    "    \"baseline\": [\"zero_shot\", \"identity\"],\n",
    "    \"letter mutation\": [\n",
    "        \"reverse_letters_in_each_word\",\n",
    "        \"swap_even_odd_letters_in_each_word\",\n",
    "        \"reverse_fibonacci_indices_in_each_word\",\n",
    "        \"letter_to_word_with_dot\",\n",
    "        \"dot_between_chars\",\n",
    "        \"space_between_chars\",\n",
    "    ],\n",
    "    \"language deletion\": [\"remove_all_verbs\", \"remove_all_nouns\"],\n",
    "    \"language translation\": [\n",
    "        \"French\",\"Chinese\",\"Korean\",\"Russian\",\"Arabic\",\"Adyghe\",\n",
    "        \"Morse_code\",\"Python\",\"enterprise_Java\",\n",
    "    ],\n",
    "    \"algorithmic cipher\": [\n",
    "        \"rot13_cipher\",\"base64_cipher\",\"base64_2x_cipher\",\n",
    "        \"base64_3x_cipher\",\"caesar_cipher\",\"gzip_to_base64_encoded\",\n",
    "    ],\n",
    "    \"themed reasoning\": [\n",
    "        \"paraphrase_naive\",\n",
    "        \"pirate_speak\",\n",
    "        \"leet_speak\",\n",
    "        \"yoda_speak\",\n",
    "        \"shakespearean_text\",\n",
    "    ],\n",
    "    \"extraneous content\": [\n",
    "        \"insert_tweet\",\n",
    "        \"python_snippet_comment\",\n",
    "        \"croissant_news_article\",\n",
    "        \"math_textbook_article\",\n",
    "        \"five_emojis\",\n",
    "    ],\n",
    "    \"delete inf.\": [\n",
    "        \"replace_math_content_with_black_box\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "l_themed_encodings = [\n",
    "    \"remove_all_verbs\",\n",
    "    \"paraphrase_naive\",\n",
    "    \"pirate_speak\",\n",
    "    \"leet_speak\",\n",
    "    \"yoda_speak\",\n",
    "    \"shakespearean_text\",\n",
    "    \"insert_tweet\",\n",
    "    \"python_snippet_comment\",\n",
    "    \"croissant_news_article\",\n",
    "    \"math_textbook_article\",\n",
    "    \"five_emojis\",\n",
    "    \"replace_math_content_with_black_box\",\n",
    "    \"reverse_letters_in_each_word_no_math_expressions\",\n",
    "    \"reverse_letters_in_each_word_only_math_expressions\"\n",
    "]\n",
    "\n",
    "l_ignore_languages = [\n",
    "    \"Russian\",\n",
    "    \"Chinese\",\n",
    "    # \"Korean\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b0308-1806-4005-80ec-d83ab4716125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.colors as pc\n",
    "\n",
    "def sample_colorscale(colorscale_name: str, n: int):\n",
    "    \"\"\"\n",
    "    Sample N equally spaced hex colors from a Plotly continuous colorscale.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    colorscale_name : str\n",
    "        Name of a Plotly built-in continuous colorscale (e.g., \"Viridis\", \"Blues\").\n",
    "    n : int\n",
    "        Number of samples to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        List of hex color strings.\n",
    "    \"\"\"\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be >= 1\")\n",
    "    colorscale = px.colors.get_colorscale(colorscale_name)\n",
    "    # equally spaced points in [0,1]\n",
    "    vals = [i/(n-1) if n > 1 else 0.5 for i in range(n)]\n",
    "    return [pc.sample_colorscale(colorscale, v)[0] for v in vals]\n",
    "\n",
    "l_gpt_gradient = sample_colorscale(\"Emrld\", 4 + 1)\n",
    "d_gpt_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['gpt-4.1-nano-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-2025-04-14', 'gpt-5-chat-latest'],\n",
    "        l_gpt_gradient[:-1]\n",
    "    )\n",
    "}\n",
    "\n",
    "l_claude_gradient = sample_colorscale(\"Purpor\", 3 + 1)\n",
    "d_claude_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['claude-3-opus-20240229', 'claude-3-5-sonnet-20241022', 'claude-sonnet-4-20250514'],\n",
    "        l_claude_gradient[1:]\n",
    "    )\n",
    "}\n",
    "\n",
    "l_qwen_gradient = sample_colorscale(\"Oryel\", 3 + 1)\n",
    "d_qwen_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['Qwen2.5-3B-Instruct', 'Qwen2.5-7B-Instruct', 'Qwen2.5-14B-Instruct'],\n",
    "        l_qwen_gradient[1:]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbea54-0ca9-49b4-a54c-12699bd2d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_star_encodings = [\n",
    "    \"reverse_letters_in_each_word\",\n",
    "    \"rot13_cipher\",\n",
    "    \"caesar_cipher\", # TODO check\n",
    " 'reverse_fibonacci_indices_in_each_word', # TODO check\n",
    " 'swap_even_odd_letters_in_each_word', # TODO check\n",
    "    \"Morse_code\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e2ffbe-0a88-412a-84ba-ef78415e4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_fixed_encoding_ordering = [\n",
    "    # GPT\n",
    " 'identity',\n",
    "'dot between chars',\n",
    " 'rot13 cipher',\n",
    " 'Korean',\n",
    " 'reverse letters in each word',\n",
    " 'letter to word with dot',\n",
    "     'base64 cipher',\n",
    " # 'remove all verbs',\n",
    "\n",
    "    # placeholder for an empty space\n",
    "    '',\n",
    "\n",
    "    # Qwen/Claude\n",
    "'space between chars',\n",
    " 'Arabic',\n",
    " 'caesar cipher',\n",
    " 'French',\n",
    " 'Adyghe',\n",
    " 'Morse code',\n",
    " 'Python',\n",
    " 'reverse fibonacci indices in each word',\n",
    " 'swap even odd letters in each word',\n",
    " 'base64 3x cipher',\n",
    " 'base64 2x cipher',\n",
    " 'remove all nouns',\n",
    " 'enterprise Java',\n",
    " 'gzip to base64 encoded'\n",
    " \n",
    "]\n",
    "\n",
    "l_fixed_encoding_ordering = [s.replace(' ', '_') for s in l_fixed_encoding_ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c55d5-a543-4d29-8438-7f8edd662956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute PGR (percent of identity performance) ---\n",
    "df_pgr = df_viz_tmp.copy()\n",
    "\n",
    "df_pgr['model'] = df_pgr['model'].str.split('Qwen/').str[-1]\n",
    "\n",
    "df_pgr = df_pgr[~df_pgr['model'].str.contains('Qwen')]\n",
    "\n",
    "# Identity baseline per model\n",
    "identity_baseline = (\n",
    "    df_pgr[df_pgr[\"encoding_scheme\"] == \"identity\"]\n",
    "    .set_index(\"model\")[\"adherent_and_correct\"]\n",
    ")\n",
    "\n",
    "df_pgr[\"identity_value\"] = np.maximum(df_pgr[\"model\"].map(identity_baseline), 0.0001)\n",
    "\n",
    "# Avoid divide-by-zero\n",
    "# df_pgr = df_pgr[df_pgr[\"identity_value\"] > 0].copy()\n",
    "\n",
    "# Mean PGR as percentage\n",
    "df_pgr[\"PGR_pct\"] = (df_pgr[\"adherent_and_correct\"] / df_pgr[\"identity_value\"])\n",
    "\n",
    "# CI deltas -> percentage deltas relative to identity baseline\n",
    "# low is negative, high is positive\n",
    "df_pgr[\"PGR_pct_hi_ci\"]  = (df_pgr[\"adherent_and_correct_hi_ci\"] / df_pgr[\"identity_value\"])\n",
    "df_pgr[\"PGR_pct_low_ci\"] = (df_pgr[\"adherent_and_correct_low_ci\"]        / df_pgr[\"identity_value\"])\n",
    "\n",
    "df_pgr.loc[df_pgr[\"encoding_scheme\"] == \"identity\", [\"PGR_pct_hi_ci\", \"PGR_pct_low_ci\"]] = 0.0\n",
    "\n",
    "# order by sonnet 4 hard coded\n",
    "# df_sonnet4 = df_pgr[df_pgr['model'].str.contains('claude-3-5-sonnet')].sort_values('adherent_and_correct', ascending=False)\n",
    "# df_sonnet4 = df_pgr[df_pgr['model'].str.contains('14B')].sort_values('adherent_and_correct', ascending=False)\n",
    "df_sonnet4 = df_pgr[df_pgr['model'].str.contains('sonnet-4')].sort_values('backtranslation_bleu_scores', ascending=False)\n",
    "\n",
    "d_encoding_scheme_to_idx = {}\n",
    "for i in range(len(df_sonnet4)):\n",
    "    d_encoding_scheme_to_idx[df_sonnet4['encoding_scheme'].iloc[i]] = i\n",
    "\n",
    "# d_encoding_scheme_to_idx['identity'] = 0\n",
    "\n",
    "# for i, encoding in enumerate(l_fixed_encoding_ordering):\n",
    "#     d_encoding_scheme_to_idx[encoding] = i\n",
    "\n",
    "df_pgr = df_pgr[~df_pgr['encoding_scheme'].isin(l_themed_encodings)]\n",
    "df_pgr = df_pgr[~df_pgr['encoding_scheme'].isin(l_ignore_languages)]\n",
    "\n",
    "df_pgr['sort_order'] = df_pgr['encoding_scheme'].map(d_encoding_scheme_to_idx)\n",
    "df_pgr = df_pgr.sort_values(['sort_order'], ascending=True)\n",
    "\n",
    "s_encoding_scheme_order = df_sonnet4['encoding_scheme']\n",
    "\n",
    "df_pgr['encoding_scheme'] = df_pgr['encoding_scheme'].map(lambda s: \" \".join(s.split('_')))\n",
    "\n",
    "df_pgr['Model Family'] = df_pgr[\"model\"].map(lambda x: \"Qwen2.5\" if \"Qwen2.5\" in x else \"GPT\" if \"gpt\" in x else \"Claude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6dcde-fa6a-4f12-8e58-d4d5d162f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_pgr[df_pgr['encoding_scheme'] != 'zero shot'],\n",
    "              x='encoding_scheme',\n",
    "              y='backtranslation_bleu_scores',\n",
    "              color='model',\n",
    "              color_discrete_map={**d_claude_gradient, **d_gpt_gradient, **d_qwen_gradient},\n",
    "              markers=True,\n",
    "              # facet_col=\"Model Family\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=dict(text=title, font=dict(size=22)),\n",
    "    template=\"plotly_white\",\n",
    "    height=500,\n",
    "    width=1800,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.08,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01,\n",
    "        font=dict(size=15)\n",
    "    ),\n",
    "    margin=dict(t=0, r=0, b=0, l=0),\n",
    "    font=dict(size=15),\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title=\"Cipher\")\n",
    "fig.update_yaxes(range=[0, 101], dtick=10, title=\"BLEU score\")\n",
    "\n",
    "fig.add_hrect(\n",
    "    y0=60, y1=100,\n",
    "    fillcolor=\"#D3D3D3\", opacity=0.4,\n",
    "    layer=\"below\", line_width=0,\n",
    "    annotation_text=\"Fluent decoding\",\n",
    "    annotation_font=dict(color=\"grey\")\n",
    ")\n",
    "\n",
    "# fig.update_layout(\n",
    "#     xaxis=dict(\n",
    "#         categoryorder=\"array\",\n",
    "#         categoryarray=s_encoding_scheme_order\n",
    "#     )\n",
    "# )\n",
    "\n",
    "fig.update_layout(width=600, height=600, title=None)\n",
    "fig.update_xaxes(tickangle=90)\n",
    "fig.update_layout(height=510, showlegend=True)\n",
    "\n",
    "fig.show('png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c117c8-674e-48ed-af9c-4ad89fdfb605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgr_save = df_pgr[['data', 'backtranslation_bleu_scores', 'encoding_scheme', 'model', 'input_type']]\n",
    "\n",
    "df_pgr_save.to_parquet(\"zero_shot_decode_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9868af0-27d2-4e49-b1fe-5a4aa97dd5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgr_save[df_pgr_save['model'] == 'gpt-4.1-2025-04-14'].drop_duplicates(subset=['model', 'encoding_scheme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbfac5-2cb8-40a8-b994-4aeed2fccdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgr[(df_pgr['model'] == 'claude-sonnet-4-20250514') & (df_pgr['encoding_scheme'] == 'base64 2x cipher')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99827cd2-b874-4e61-a785-650ff7883964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/home/ubuntu/sky_workdir/encoding-schemes/output/63fec9362cf90b227d87cbade5c65dab5003e0fb/data/joined_output.parquet\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576f1368-a733-4448-95da-beeb14f50f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91cf072-d5a9-4fab-8dc4-084a1676ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['translated_solution'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd2273-3ee1-46cb-9fb0-2bc45997c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['generated_backtranslations'].iloc[idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4699ba6a-c6eb-49bb-8f15-8a88754732f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['backtranslation_bleu_scores'].iloc[idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec150168-c60e-403a-bd0b-f639d6f56034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
