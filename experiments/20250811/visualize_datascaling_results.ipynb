{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d0a44-0aae-4a22-9ea2-552f1efd9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31791de-bdbf-44f4-ac17-de4f754d0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/sky_workdir/encoding-schemes\")\n",
    "\n",
    "from encoding_schemes import get_deterministic_adherence_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8432f-7bb7-4bb8-8223-ea329456a590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8ad9e-91d3-4e3b-b25c-9f19f3e4b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "conn_string = os.environ[\"SUPABASE_CONNECTION_URL\"]\n",
    "\n",
    "conn = psycopg2.connect(conn_string)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b3a2c-ade1-42ca-a798-5b94232485d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_str = \"\"\"\n",
    "-- data scaling qwen\n",
    " (\n",
    "     (NOT (data->'force_overwrite')::BOOL OR data->'force_overwrite' IS NULL)\n",
    "     AND (\n",
    "         (data->'experiment_name')::TEXT LIKE '%datascaling%'\n",
    "     )\n",
    "  ) OR\n",
    "-- OpenAI SFT\n",
    "(\n",
    "     (data->'experiment_tags'->'numina_math_cot_rerun')::BOOL\n",
    "     AND (NOT (data->'force_overwrite')::BOOL OR data->'force_overwrite' IS NULL)\n",
    "     AND (\n",
    "         ((data->'experiment_params'->'model')::TEXT LIKE '%gpt%' AND (data->'experiment_params'->'sft_params'->'batch_size')::INT != 48)\n",
    "     )\n",
    "     AND (data->'experiment_name')::TEXT LIKE '%math_cot%'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(f\"\"\"\n",
    "SELECT * FROM public.encoding_schemes \n",
    "    WHERE \n",
    "\n",
    "{sel_str}\n",
    "\n",
    "\n",
    "ORDER BY created_at DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439f59a-7755-482d-ac55-c324ac5bed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/ubuntu/sky_workdir/encoding-schemes/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef482ac-2bcb-46ad-81d0-1a2e523a92e7",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a81ec-f561-430e-8570-c9d4a2a0f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap_ci(data, statistic=np.mean, alpha=0.05, n_boot=10_000, random_state=None):\n",
    "    \"\"\"\n",
    "    Returns (point_estimate, low_CI, high_CI) for given 1D data.\n",
    "    Works with bool, int, or float data.\n",
    "    \"\"\"\n",
    "    x = np.asarray(data).astype(float)  # ensure numeric\n",
    "    x = x[~np.isnan(x)]\n",
    "    if len(x) == 0:\n",
    "        raise ValueError(\"No valid data for bootstrapping.\")\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(x)\n",
    "\n",
    "    # Draw bootstrap samples\n",
    "    idx = rng.integers(0, n, size=(n_boot, n))\n",
    "    samples = x[idx]\n",
    "\n",
    "    # Apply statistic row-wise\n",
    "    stats = np.apply_along_axis(statistic, 1, samples)\n",
    "\n",
    "    point = statistic(x)\n",
    "    lo = np.percentile(stats, 100 * (alpha / 2))\n",
    "    hi = np.percentile(stats, 100 * (1 - alpha / 2))\n",
    "    return point, lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fb9f9-33d1-4e61-b837-cc8b37219291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def count_tokens_from_messages(s):\n",
    "    try:\n",
    "        return len(encoding.encode(s, disallowed_special=()))\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db9fcc-ffa9-4a77-ad34-88067f4d63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=2, memory=32 * 1024 * 1024 * 1024)\n",
    "def compute_translation_token_count(example, df_data):\n",
    "    sys.path.append(\"/home/ubuntu/sky_workdir/encoding-schemes\")\n",
    "\n",
    "    from orchestration.experiment_meta_saver import compute_experiment_hash\n",
    "    from utils.io_utils import read_large_parquet\n",
    "\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    model = example[\"data\"][\"experiment_params\"][\"model\"]\n",
    "    if \"gpt\" in model or \"claude\" in model:\n",
    "        print(f\"Overriding tokenizer for {model} with gpt-oss 120b tokenizer because it was detected as a GPT/Claude model!\")\n",
    "        model = \"openai/gpt-oss-120b\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "    return df_data['reference_solution'].map(lambda x: len(tokenizer.encode(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f84e71-0f86-4e06-b744-96e3e6a71ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231976a-7a7d-4f2a-90f8-eaa70083c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ci_cols(example, df, col_name, transformation_fn):\n",
    "    s_transformed = transformation_fn(df[col_name])\n",
    "    if np.isscalar(s_transformed) and np.isnan(s_transformed):\n",
    "        print(f\"Warning: {col_name} was all NaN, ignoring!\")\n",
    "        return\n",
    "    mid, lo, hi = bootstrap_ci(s_transformed)\n",
    "    example[col_name] = mid\n",
    "    example[f'{col_name}_low_ci'] = mid - lo\n",
    "    example[f'{col_name}_hi_ci'] = hi - mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1d5fd-3931-4206-a956-9704eae789ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multi_row_transformation(df, row_transform_fn, col_name, agg_fn):\n",
    "    df[col_name] = df.apply(row_transform_fn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73907c00-ce16-4bce-b6e9-14d9bb68e0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def _score_rollouts(rollouts):\n",
    "    # rollouts: list/array of rollout sequences; may also be None/np.nan/scalar\n",
    "    if rollouts is None or (isinstance(rollouts, float) and np.isnan(rollouts)):\n",
    "        return np.nan\n",
    "\n",
    "    vals = []\n",
    "    for r in rollouts:\n",
    "        # skip None/NaN\n",
    "        if r is None or (isinstance(r, float) and np.isnan(r)):\n",
    "            continue\n",
    "        vals.append(-np.nansum(r))\n",
    "    return np.nanmean(vals) if len(vals) else np.nan\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def process_single_example(example, step):\n",
    "    model_name = example[\"data\"][\"experiment_params\"][\"model\"]\n",
    "    \n",
    "    experiment_hash = example['experiment_hash']\n",
    "\n",
    "    if \"gpt\" in model_name:\n",
    "        step_prefix = \"\"\n",
    "    else:\n",
    "        step_prefix = f\"processed_{step}\"\n",
    "    target_path = os.path.join(root_dir, example['experiment_hash'], \"data\", step_prefix, \"joined_output.parquet\")\n",
    "    if not os.path.exists(target_path):\n",
    "        print(f\"!!!!!! {target_path} missing !!!!!!!\")\n",
    "        return example\n",
    "    \n",
    "    df_data = pd.read_parquet(target_path)\n",
    "\n",
    "    d_col_to_transform = {\n",
    "        'cot_gt_logprobs' : lambda s: np.nansum(s.map(_score_rollouts)),\n",
    "        'generated_cot_is_correct' : np.mean,  # was np.mean\n",
    "        'backtranslation_gt_logprobs' : lambda s: np.nanmean(s.map(_score_rollouts)),\n",
    "        'backtranslation_bleu_scores' : np.mean,  # was np.mean\n",
    "        'generated_cot_adhered_encoding_style': np.mean  # was np.mean\n",
    "    }\n",
    "    for col, fn in d_col_to_transform.items():\n",
    "        if col not in df_data:\n",
    "            print(col)\n",
    "            print(df_data.head())\n",
    "            print(example)\n",
    "            raise Exception(str(col) + \"\\n\" + str(df_data.head()) + \"\\n\" + str(example))\n",
    "\n",
    "        compute_ci_cols(example, df_data, col, fn)\n",
    "\n",
    "    df_data[\"num_tokens_translation_output\"] = ray.get(compute_translation_token_count.remote(example, df_data))\n",
    "\n",
    "    d_and_cols = {\n",
    "        'adherent_and_correct': (\n",
    "            lambda r: np.nanmean( \\\n",
    "                np.array(r['generated_cot_is_correct']).astype(bool) & \\\n",
    "                np.array(r['generated_cot_adhered_encoding_style']).astype(bool) \\\n",
    "            ),\n",
    "            np.nanmean\n",
    "        ),\n",
    "        'total_translation_loss': (\n",
    "            lambda r: np.nanmean( \\\n",
    "                np.array(r['num_tokens_translation_output']) * \\\n",
    "                np.array(np.nanmean(_score_rollouts(r['backtranslation_gt_logprobs'])), dtype=np.float64) \\\n",
    "            ),\n",
    "            np.nanmean\n",
    "        ),\n",
    "    }\n",
    "    for col, (transform_fn, agg_fn) in d_and_cols.items():\n",
    "        compute_multi_row_transformation(df_data, transform_fn, col, agg_fn)\n",
    "        if df_data[col].isna().sum() != len(df_data):\n",
    "            compute_ci_cols(example, df_data, col, lambda x: x)\n",
    "\n",
    "    for col in df_data.columns:\n",
    "        example[f\"{col}_df\"] = df_data[col]\n",
    "\n",
    "    if \"gpt\" in model_name and \"use_api_sft_model_for_sampling\" in example[\"data\"][\"experiment_params\"]:\n",
    "        with open(os.path.join(root_dir, example['experiment_hash'], \"data\", f\"validation_numinamath_validation_meta.json\"), \"r\") as fp:\n",
    "            d_model_meta = json.load(fp)\n",
    "\n",
    "        df_valid = duckdb.query(f\"SELECT num_tokens FROM '{os.path.join(root_dir, example['experiment_hash'], 'data', 'sft.parquet')}'\").to_df()\n",
    "\n",
    "        example[\"total_validation_loss\"] = d_model_meta[\"valid_loss\"] * np.nansum(df_valid['num_tokens'])\n",
    "\n",
    "        with open(os.path.join(root_dir, example['experiment_hash'], \"data\", f\"validation_reverse_translation_math500_meta.json\"), \"r\") as fp:\n",
    "            d_model_meta = json.load(fp)\n",
    "\n",
    "        example[\"backtranslation_gt_logprobs\"] = d_model_meta[\"valid_loss\"]\n",
    "        example[\"total_translation_loss\"] = d_model_meta[\"valid_loss\"] * np.nanmean(df_data[\"num_tokens_translation_output\"])\n",
    "    else:\n",
    "        # Append # training toks\n",
    "        example['training_step'] = step\n",
    "    \n",
    "        df_sft = duckdb.query(f\"SELECT num_tokens FROM '{os.path.join(root_dir, example['experiment_hash'], 'data', 'sft_train.parquet')}'\").to_df()\n",
    "        batch_size = example['data']['experiment_params']['sft_params']['batch_size']\n",
    "        example['num_training_tokens'] = df_sft.iloc[:step * batch_size]['num_tokens'].sum()\n",
    "        example['mean_training_token_length'] = df_sft.iloc[:step * batch_size]['num_tokens'].mean()\n",
    "\n",
    "        try:\n",
    "            df_valid_logprobs = duckdb.query(f\"SELECT gt_logprobs FROM '{os.path.join(root_dir, example['experiment_hash'], 'data', step_prefix, 'valid_logprobs.parquet')}'\").to_df()\n",
    "            example['mean_valid_sequence_log_loss'] = np.nanmean([\n",
    "                -np.nansum(r['gt_logprobs'])\n",
    "                for _, r in df_valid_logprobs.iterrows()\n",
    "            ])\n",
    "    \n",
    "            example['total_validation_loss'] = np.nansum([\n",
    "                -np.nansum(r['gt_logprobs'])\n",
    "                for _, r in df_valid_logprobs.iterrows()\n",
    "            ])\n",
    "    \n",
    "            example['total_total_translation_loss'] = np.nansum([\n",
    "                -np.nansum(r['backtranslation_gt_logprobs'])\n",
    "                for _, r in df_data.iterrows()\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return example\n",
    "\n",
    "l_examples = df.to_dict('records')\n",
    "\n",
    "l_steps = [128, 256, 512, 1024, 2048, 3712]\n",
    "l_new_examples = [None for _ in range(len(l_examples) * len(l_steps))]\n",
    "\n",
    "for i, example in tqdm(enumerate(l_examples)):\n",
    "    for j in range(len(l_steps)):\n",
    "        # l_examples[i] = process_single_example(example)\n",
    "        l_new_examples[i * len(l_steps) + j] = process_single_example.remote(example, l_steps[j])\n",
    "\n",
    "for i, example in tqdm(enumerate(l_new_examples)):\n",
    "    try:\n",
    "        l_new_examples[i] = ray.get(example)\n",
    "    except ray.exceptions.RayTaskError as e:\n",
    "        # l_new_examples[i] = l_examples[i]\n",
    "        l_new_examples[i] = {}\n",
    "        print(e)\n",
    "\n",
    "l_examples = l_new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8382e4e-2242-48ce-98de-acec6dcff3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_examples = [e for e in l_examples if e != {}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7b0cc-4d72-4780-9f3a-0fa25ee3a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize_number(num: float) -> str:\n",
    "    \"\"\"\n",
    "    Converts a number into a human-readable string with k, M, or B suffixes.\n",
    "    \n",
    "    Args:\n",
    "        num (float): The number to format.\n",
    "    \n",
    "    Returns:\n",
    "        str: Human-readable string representation.\n",
    "    \"\"\"\n",
    "    if num >= 1_000_000_000:\n",
    "        return f\"{num / 1_000_000_000:.1f}B\"\n",
    "    elif num >= 1_000_000:\n",
    "        return f\"{num / 1_000_000:.1f}M\"\n",
    "    elif num >= 1_000:\n",
    "        return f\"{num / 1_000:.1f}k\"\n",
    "    else:\n",
    "        return str(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c8aa3-b7b1-48a7-b0fc-c8811fe9a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_params(model):\n",
    "    if 'gpt' in model:\n",
    "        if 'nano' in model:\n",
    "            return 0\n",
    "        elif 'mini' in model:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "\n",
    "    if 'claude' in model:\n",
    "        if 'haiku' in model:\n",
    "            return 3\n",
    "        elif 'sonnet' in model:\n",
    "            return 4\n",
    "        else:\n",
    "            return 5\n",
    "    \n",
    "    return int(re.search(\"([0-9]+)B\", model).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a412a1f-de17-4d22-b798-12ea8ce0db67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_viz = pd.DataFrame(l_examples)\n",
    "\n",
    "orig_len = len(df_viz)\n",
    "\n",
    "# df_viz = df_viz[df_viz['cot_gt_logprobs'].notna()]\n",
    "\n",
    "new_len = len(df_viz)\n",
    "if orig_len != new_len:\n",
    "    print(f\"Lost {orig_len - new_len} examples from na logprobs\")\n",
    "\n",
    "df_viz['encoding_scheme'] = df_viz['data'].map(lambda x: x['experiment_params']['encoding_scheme'])\n",
    "df_viz['model'] = df_viz['data'].map(lambda x: x['experiment_params']['model'])\n",
    "\n",
    "try:\n",
    "    df_viz['model_size'] = df_viz['model'].map(parse_params)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "df_viz['input_type'] = df_viz['data'].map(lambda x: \"_\".join(x['experiment_name'].split(\"_\")[:2]))\n",
    "\n",
    "df_viz['n_few_shot_examples'] = df_viz['data'].map(lambda x: x['experiment_params'].get('n_few_shot_examples', None))\n",
    "\n",
    "df_viz['Adherence Calculation Method'] = df_viz['encoding_scheme'].map(lambda x: get_deterministic_adherence_fn(x, None) is not None).map({ True: 'deterministic', False: 'Sonnet 4 judge'})\n",
    "\n",
    "try:\n",
    "    df_viz['total_train_tok'] = df_viz['n_total_train_tok'].map(humanize_number)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "df_viz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59da245-a8a4-482d-b5a8-814c663f4cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz['input_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d5f60-3ce3-448f-b887-0d0723e8a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_set = ['datascaling_mathcot', 'math_cot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294af9ce-482f-4336-a8bc-6aaf90027383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp = df_viz[df_viz['input_type'].isin(filter_set)]\n",
    "df_viz_tmp = df_viz_tmp[df_viz_tmp['model'] != 'Qwen/Qwen2.5-7B']\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.sort_values([\n",
    "    'num_training_tokens',\n",
    "    'model_size'\n",
    "])\n",
    "\n",
    "df_viz_tmp = df_viz_tmp.astype({'n_few_shot_examples': str})\n",
    "df_viz_tmp['model'] = df_viz_tmp['model'].str.split('Qwen/').str[-1]\n",
    "\n",
    "df_viz_tmp['encoding_scheme'] = df_viz_tmp['encoding_scheme'].map(lambda s: s.split(\"speaking_\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ecdc1-724c-4702-8b38-bf548beafa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QWEN25_INSTRUCT_CONFIGS = {\n",
    "    \"Qwen2.5-0.5B-Instruct\": {\n",
    "        \"hidden_size\": 896,\n",
    "        \"vocab_size\": 151936,\n",
    "        \"num_hidden_layers\": 24,\n",
    "        \"num_key_value_heads\": 2,\n",
    "        \"num_attention_heads\": 14,\n",
    "        \"intermediate_size\": 4864,\n",
    "    },\n",
    "    \"Qwen2.5-1.5B-Instruct\": {\n",
    "        \"hidden_size\": 1536,\n",
    "        \"vocab_size\": 151936,\n",
    "        \"num_hidden_layers\": 28,\n",
    "        \"num_key_value_heads\": 2,\n",
    "        \"num_attention_heads\": 12,\n",
    "        \"intermediate_size\": 8960,\n",
    "    },\n",
    "    \"Qwen2.5-3B-Instruct\": {\n",
    "        \"hidden_size\": 2048,\n",
    "        \"vocab_size\": 151936,\n",
    "        \"num_hidden_layers\": 36,\n",
    "        \"num_key_value_heads\": 2,\n",
    "        \"num_attention_heads\": 16,\n",
    "        \"intermediate_size\": 11008,\n",
    "    },\n",
    "    \"Qwen2.5-7B-Instruct\": {\n",
    "        \"hidden_size\": 3584,\n",
    "        \"vocab_size\": 152064,\n",
    "        \"num_hidden_layers\": 28,\n",
    "        \"num_key_value_heads\": 4,\n",
    "        \"num_attention_heads\": 28,\n",
    "        \"intermediate_size\": 18944,\n",
    "    },\n",
    "    \"Qwen2.5-14B-Instruct\": {\n",
    "        \"hidden_size\": 5120,\n",
    "        \"vocab_size\": 152064,\n",
    "        \"num_hidden_layers\": 48,\n",
    "        \"num_key_value_heads\": 8,\n",
    "        \"num_attention_heads\": 40,\n",
    "        \"intermediate_size\": 13824,\n",
    "    },\n",
    "    \"Qwen2.5-32B-Instruct\": {\n",
    "        \"hidden_size\": 5120,\n",
    "        \"vocab_size\": 152064,\n",
    "        \"num_hidden_layers\": 64,\n",
    "        \"num_key_value_heads\": 8,\n",
    "        \"num_attention_heads\": 40,\n",
    "        \"intermediate_size\": 27648,\n",
    "    },\n",
    "    \"Qwen2.5-72B-Instruct\": {\n",
    "        \"hidden_size\": 8192,\n",
    "        \"vocab_size\": 152064,\n",
    "        \"num_hidden_layers\": 80,\n",
    "        \"num_key_value_heads\": 8,\n",
    "        \"num_attention_heads\": 64,\n",
    "        \"intermediate_size\": 29568,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# taken from verl\n",
    "def _estimate_qwen2_flops(hidden_size, vocab_size, num_hidden_layers, num_key_value_heads, num_attention_heads, intermediate_size, tokens_sum, batch_seqlens):\n",
    "    hidden_size = hidden_size\n",
    "    vocab_size = vocab_size\n",
    "    num_hidden_layers = num_hidden_layers\n",
    "    num_key_value_heads = num_key_value_heads\n",
    "    num_attention_heads = num_attention_heads\n",
    "    intermediate_size = intermediate_size\n",
    "\n",
    "    head_dim = hidden_size // num_attention_heads\n",
    "    q_size = num_attention_heads * head_dim\n",
    "    k_size = num_key_value_heads * head_dim\n",
    "    v_size = num_key_value_heads * head_dim\n",
    "\n",
    "    # non-attn per layer parm\n",
    "    # Qwen2/LLama use SwiGelu, gate, having up and down linear layer in mlp\n",
    "    mlp_N = hidden_size * intermediate_size * 3\n",
    "    attn_linear_N = hidden_size * (q_size + k_size + v_size + num_attention_heads * head_dim)\n",
    "    emd_and_lm_head_N = vocab_size * hidden_size * 2\n",
    "    # non-attn all_layer parm\n",
    "    dense_N = (mlp_N + attn_linear_N) * num_hidden_layers + emd_and_lm_head_N\n",
    "    # non-attn all_layer & all_token fwd & bwd flops\n",
    "    dense_N_flops = 6 * dense_N * tokens_sum\n",
    "\n",
    "    # attn all_layer & all_token fwd & bwd flops\n",
    "    seqlen_square_sum = 0\n",
    "    for seqlen in batch_seqlens:\n",
    "        seqlen_square_sum += seqlen * seqlen\n",
    "    attn_qkv_flops = 12 * seqlen_square_sum * head_dim * num_attention_heads * num_hidden_layers\n",
    "\n",
    "    # all_layer & all_token fwd & bwd flops\n",
    "    flops_all_token = dense_N_flops + attn_qkv_flops\n",
    "    return flops_all_token\n",
    "\n",
    "\n",
    "df_viz_tmp.loc[df_viz_tmp['model'].str.contains('Qwen'), 'training_flops'] = df_viz_tmp.loc[df_viz_tmp['model'].str.contains('Qwen'), :].apply(lambda row: _estimate_qwen2_flops(**QWEN25_INSTRUCT_CONFIGS[row['model']], \\\n",
    "                                                                                  tokens_sum=row['num_training_tokens'], \\\n",
    "                                                                                  batch_seqlens=[row['mean_training_token_length'] for _ in range(row['data']['experiment_params']['sft_params']['batch_size'])]), axis=1) * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a828d6-6815-4381-b995-20982640f527",
   "metadata": {},
   "source": [
    "# Paper plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b6ab3-4ecf-4e5c-9ce2-dc9d3a6cd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.colors as pc\n",
    "\n",
    "def sample_colorscale(colorscale_name: str, n: int):\n",
    "    \"\"\"\n",
    "    Sample N equally spaced hex colors from a Plotly continuous colorscale.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    colorscale_name : str\n",
    "        Name of a Plotly built-in continuous colorscale (e.g., \"Viridis\", \"Blues\").\n",
    "    n : int\n",
    "        Number of samples to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        List of hex color strings.\n",
    "    \"\"\"\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be >= 1\")\n",
    "    colorscale = px.colors.get_colorscale(colorscale_name)\n",
    "    # equally spaced points in [0,1]\n",
    "    vals = [i/(n-1) if n > 1 else 0.5 for i in range(n)]\n",
    "    return [pc.sample_colorscale(colorscale, v)[0] for v in vals]\n",
    "\n",
    "l_gpt_gradient = sample_colorscale(\"Emrld\", 4 + 1)\n",
    "d_gpt_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['gpt-4.1-nano-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-2025-04-14', 'gpt-5-chat-latest'],\n",
    "        l_gpt_gradient[1:]\n",
    "    )\n",
    "}\n",
    "\n",
    "l_claude_gradient = sample_colorscale(\"Magenta\", 3 + 1)\n",
    "d_claude_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['claude-3-opus-20240229', 'claude-3-5-sonnet-20241022', 'claude-sonnet-4-20250514'],\n",
    "        l_claude_gradient[1:]\n",
    "    )\n",
    "}\n",
    "\n",
    "l_qwen_gradient = sample_colorscale(\"Oryel\", 3 + 1)\n",
    "d_qwen_gradient = {\n",
    "    model : color\n",
    "    for model, color in zip(\n",
    "        ['Qwen2.5-3B', 'Qwen2.5-7B', 'Qwen2.5-14B'],\n",
    "        l_qwen_gradient[1:]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73746c62-cffd-48a8-827d-dcfd9cd778cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp['model'] = df_viz_tmp['model'].str.split('-Instruct').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33d894-e729-4149-95d6-2e3eeb8c0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_viz_tmp[(df_viz_tmp['encoding_scheme'] == 'letter_to_word_with_dot') & (df_viz_tmp['model'].str.contains('Qwen'))],\n",
    "              x='num_training_tokens', y='adherent_and_correct', color='model',  markers=True, log_x=True,\n",
    "             color_discrete_map=d_qwen_gradient)\n",
    "\n",
    "fig.update_layout(height=400, width=525, template=\"plotly_white\", font=dict(size=15), showlegend=False)\n",
    "fig.update_yaxes(title=\"% adherent & correct responses\")\n",
    "fig.update_xaxes(title=\"# fine-tuning tokens\")\n",
    "\n",
    "df_for_labels = df_viz_tmp[(df_viz_tmp['encoding_scheme'] == 'letter_to_word_with_dot') & (df_viz_tmp['model'].str.contains('Qwen'))]\n",
    "for model in df_for_labels['model'].unique():\n",
    "    model_data = df_for_labels[df_for_labels['model'] == model]\n",
    "    # Get the point with maximum x value (rightmost point)\n",
    "    max_x_row = model_data.loc[model_data['num_training_tokens'].idxmax()]\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=np.log10(max_x_row['num_training_tokens']),\n",
    "        y=max_x_row['adherent_and_correct'],\n",
    "        text=model.split('2.5-')[1] if '2.5-' in model else model,\n",
    "        showarrow=False,\n",
    "        xanchor='left',\n",
    "        yanchor='middle',\n",
    "        xshift=10,\n",
    "        font=dict(size=16, color=d_qwen_gradient.get(model, 'black')),\n",
    "    )\n",
    "\n",
    "\n",
    "def format_tokens(value):\n",
    "    if value >= 1_000_000_000:\n",
    "        return f'{value/1_000_000_000:.0f}B' if value % 1_000_000_000 == 0 else f'{value/1_000_000_000:.1f}B'\n",
    "    elif value >= 1_000_000:\n",
    "        return f'{value/1_000_000:.0f}M' if value % 1_000_000 == 0 else f'{value/1_000_000:.1f}M'\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "# Generate tickvals based on your data range\n",
    "tickvals = [100_000_000, 200_000_000, 500_000_000, 1_000_000_000, 2_000_000_000, 5_000_000_000]\n",
    "ticktext = [format_tokens(val) for val in tickvals]\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title=\"# fine-tuning tokens\",\n",
    "    tickvals=tickvals,\n",
    "    ticktext=ticktext,\n",
    "    tickmode='array'\n",
    ")\n",
    "\n",
    "for _, row in df_viz_tmp[df_viz_tmp['model'].str.contains('Qwen')].sort_values('adherent_and_correct', ascending=False).drop_duplicates(subset=['model', 'encoding_scheme'], keep='first').iterrows():\n",
    "    if row['encoding_scheme'] == 'identity' and ('7B' in row['model'] or '14B' in row['model']):\n",
    "        print(row['adherent_and_correct'], row['model'])\n",
    "        fig.add_hline(y=row['adherent_and_correct'], annotation_text=row['model'].split('2.5-')[1] + \" unciphered\", line_dash='dot', line=dict(color='rgba(0, 0, 0, 0.3)'), annotation_position=\"top left\", annotation_font_color='#878787',)\n",
    "    elif row['encoding_scheme'] == 'zero_shot'  and ('14B' in row['model']):\n",
    "        fig.add_hline(y=row['adherent_and_correct'], annotation_text=row['model'].split('2.5-')[1] + \" direct answering\", line_dash='dot', line=dict(color='rgba(0, 0, 0, 0.3)'), annotation_position=\"top left\", annotation_font_color='#878787',)\n",
    "\n",
    "plotly.io.write_image(fig, 'datascaling_math_score.pdf', format='pdf')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dcecc-2ca6-4ffe-9aee-e43f1e7845d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pgr = []\n",
    "for _, row in df_viz_tmp.iterrows():\n",
    "    df_search = df_viz_tmp[(df_viz_tmp['encoding_scheme'] == 'identity') & (df_viz_tmp['model'] == row['model'])]\n",
    "    pgr = row['adherent_and_correct'] / df_search['adherent_and_correct'].max()\n",
    "    # gen discriminator gap\n",
    "    # l_pgr.append(pgr - (row['backtranslation_bleu_scores'] / 100))\n",
    "    # PGR\n",
    "    l_pgr.append(pgr)\n",
    "df_viz_tmp['PGR_pct'] = l_pgr\n",
    "\n",
    "fig = px.line(df_viz_tmp[(df_viz_tmp['encoding_scheme'] == 'letter_to_word_with_dot') & (df_viz_tmp['model'].str.contains('Qwen'))],\n",
    "              x='training_flops', y='PGR_pct', color='model',  markers=True, log_x=True,\n",
    "             color_discrete_map=d_qwen_gradient)\n",
    "\n",
    "fig.update_layout(height=400, width=525, template=\"plotly_white\", font=dict(size=15))\n",
    "fig.update_yaxes(title=\"PGR\")#, range=[-0.8, 0])\n",
    "fig.update_xaxes(title=\"Fine-tuning FLOPs\")\n",
    "\n",
    "# for _, row in df_viz_tmp[df_viz_tmp['model'].str.contains('Qwen')].sort_values('adherent_and_correct', ascending=False).drop_duplicates(subset=['model', 'encoding_scheme'], keep='first').iterrows():\n",
    "#     if row['encoding_scheme'] == 'identity':\n",
    "#         fig.add_hline(y=row['adherent_and_correct'], annotation_text=row['model'].split('2.5-')[1] + \" unencoded\", line_dash='dash', line=dict(color='rgba(0, 0, 0, 0.3)'), annotation_position=\"top left\")\n",
    "\n",
    "fig.show('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be45c83-dd26-4383-b27f-793861d98d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_viz_tmp[(df_viz_tmp['encoding_scheme'] == 'letter_to_word_with_dot') & (df_viz_tmp['model'].str.contains('Qwen'))],\n",
    "              x='num_training_tokens', y='backtranslation_bleu_scores', color='model', markers=True, log_x=True, color_discrete_map=d_qwen_gradient)\n",
    "\n",
    "fig.update_layout(height=400, width=525, template=\"plotly_white\", font=dict(size=15), showlegend=False)\n",
    "fig.update_yaxes(title=\"BLEU score\")\n",
    "fig.update_xaxes(title=\"# fine-tuning tokens\")\n",
    "\n",
    "df_for_labels = df_viz_tmp[(df_viz_tmp['encoding_scheme'] == 'letter_to_word_with_dot') & (df_viz_tmp['model'].str.contains('Qwen'))]\n",
    "for model in df_for_labels['model'].unique():\n",
    "    model_data = df_for_labels[df_for_labels['model'] == model]\n",
    "    # Get the point with maximum x value (rightmost point)\n",
    "    max_x_row = model_data.loc[model_data['num_training_tokens'].idxmin()]\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=np.log10(max_x_row['num_training_tokens']),\n",
    "        y=max_x_row['backtranslation_bleu_scores'],\n",
    "        text=model.split('2.5-')[1] if '2.5-' in model else model,\n",
    "        showarrow=False,\n",
    "        xanchor='right',\n",
    "        yanchor='middle',\n",
    "        xshift=-10,\n",
    "        font=dict(size=16, color=d_qwen_gradient.get(model, 'black')),\n",
    "    )\n",
    "\n",
    "\n",
    "def format_tokens(value):\n",
    "    if value >= 1_000_000_000:\n",
    "        return f'{value/1_000_000_000:.0f}B' if value % 1_000_000_000 == 0 else f'{value/1_000_000_000:.1f}B'\n",
    "    elif value >= 1_000_000:\n",
    "        return f'{value/1_000_000:.0f}M' if value % 1_000_000 == 0 else f'{value/1_000_000:.1f}M'\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "# Generate tickvals based on your data range\n",
    "tickvals = [100_000_000, 200_000_000, 500_000_000, 1_000_000_000, 2_000_000_000, 5_000_000_000]\n",
    "ticktext = [format_tokens(val) for val in tickvals]\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title=\"# fine-tuning tokens\",\n",
    "    tickvals=tickvals,\n",
    "    ticktext=ticktext,\n",
    "    tickmode='array'\n",
    ")\n",
    "\n",
    "plotly.io.write_image(fig, 'datascaling_translation_bleu.pdf', format='pdf')\n",
    "\n",
    "fig.show('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc38fe-8b86-4803-aba7-ed923ab78c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_viz_tmp[(df_viz_tmp['encoding_scheme'] == 'letter_to_word_with_dot') & (df_viz_tmp['model'].str.contains('Qwen'))],\n",
    "              x='training_flops', y='total_translation_loss', color='model', markers=True, log_x=True, color_discrete_map=d_qwen_gradient)\n",
    "\n",
    "fig.update_layout(height=400, width=525, template=\"plotly_white\", font=dict(size=15))\n",
    "fig.update_yaxes(title=\"Total decoding loss\")\n",
    "fig.update_xaxes(title=\"Fine-tuning FLOPs\")\n",
    "\n",
    "for _, row in df_viz_tmp[df_viz_tmp['model'].str.contains('gpt')].drop_duplicates(subset=['model', 'encoding_scheme']).iterrows():\n",
    "    if row['encoding_scheme'] == 'dot_between_chars':\n",
    "        fig.add_hline(y=row['total_translation_loss'], annotation_text=row['model'].split('-2025')[0] + \"-SFT\", line_dash='dash', line=dict(color='rgba(0, 0, 0, 0.3)'), annotation_position=\"top right\" if \"gpt-4.1-2025\" in row['model'] else \"top left\")\n",
    "# TODO: add GPT 4.1 series here!\n",
    "\n",
    "fig.show('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc8e16-f304-479d-8061-910a14bd07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_viz_tmp[(df_viz_tmp['encoding_scheme'] == 'letter_to_word_with_dot') & (df_viz_tmp['model'].str.contains('Qwen'))],\n",
    "              x='training_flops', y='mean_valid_sequence_log_loss', color='model', markers=True, log_x=True, color_discrete_map=d_qwen_gradient)\n",
    "\n",
    "fig.update_layout(height=400, width=525, template=\"plotly_white\")\n",
    "fig.update_yaxes(title=\"Mean per-sequence loss, valid set\")\n",
    "fig.update_xaxes(title=\"Fine-tuning FLOPs\")\n",
    "\n",
    "fig.show('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f3197-24e3-4507-80b9-5f59d1b0994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_tmp[df_viz_tmp['model'].str.contains('14B') & (df_viz_tmp['encoding_scheme'] == 'letter_to_word_with_dot')].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14faa3-3d0e-4349-bc65-ff262a7aba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_parquet(\"/home/ubuntu/sky_workdir/encoding-schemes/output/3863e9f29ee0a696a4f056d96cdfb694506f8202/data/sft.parquet\")\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97abfa2-ee99-48bb-a33b-db7f7dc4761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"SELECT SUM(num_tokens) FROM '/home/ubuntu/sky_workdir/encoding-schemes/output/e3f76d94751a09af21005696ac072219143ebc58/data/sft_train.parquet'\").to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811717f-8ac3-4fa2-9bc8-fa9c758c6aad",
   "metadata": {},
   "source": [
    "# grid scaling laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ad3a6-d869-4caa-a51a-beff5d278fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for encoding_scheme in ['dot_between_chars', 'zero_shot', 'identity']:\n",
    "    fig = px.line(df_viz_tmp[(df_viz_tmp['encoding_scheme'] == encoding_scheme) & (df_viz_tmp['model'].str.contains('Qwen'))],\n",
    "                  x='num_training_tokens', y='adherent_and_correct', color='model',  markers=True, log_x=True,\n",
    "                 color_discrete_map=d_qwen_gradient)\n",
    "    \n",
    "    fig.update_layout(height=400, width=525, template=\"plotly_white\", font=dict(size=15), showlegend=False)\n",
    "    fig.update_yaxes(title=\"% adherent & correct responses\")\n",
    "    fig.update_xaxes(title=\"# fine-tuning tokens\")\n",
    "    \n",
    "    df_for_labels = df_viz_tmp[(df_viz_tmp['encoding_scheme'] == encoding_scheme) & (df_viz_tmp['model'].str.contains('Qwen'))]\n",
    "    for model in df_for_labels['model'].unique():\n",
    "        model_data = df_for_labels[df_for_labels['model'] == model]\n",
    "        # Get the point with maximum x value (rightmost point)\n",
    "        max_x_row = model_data.loc[model_data['num_training_tokens'].idxmax()]\n",
    "        \n",
    "        fig.add_annotation(\n",
    "            x=np.log10(max_x_row['num_training_tokens']),\n",
    "            y=max_x_row['adherent_and_correct'],\n",
    "            text=model.split('2.5-')[1] if '2.5-' in model else model,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            yanchor='middle',\n",
    "            xshift=10,\n",
    "            font=dict(size=16, color=d_qwen_gradient.get(model, 'black')),\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def format_tokens(value):\n",
    "        if value >= 1_000_000_000:\n",
    "            return f'{value/1_000_000_000:.0f}B' if value % 1_000_000_000 == 0 else f'{value/1_000_000_000:.1f}B'\n",
    "        elif value >= 1_000_000:\n",
    "            return f'{value/1_000_000:.0f}M' if value % 1_000_000 == 0 else f'{value/1_000_000:.1f}M'\n",
    "        else:\n",
    "            return str(value)\n",
    "    \n",
    "    # Generate tickvals based on your data range\n",
    "    tickvals = [100_000_000, 200_000_000, 500_000_000, 1_000_000_000, 2_000_000_000, 5_000_000_000]\n",
    "    ticktext = [format_tokens(val) for val in tickvals]\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        title=\"# fine-tuning tokens\",\n",
    "        tickvals=tickvals,\n",
    "        ticktext=ticktext,\n",
    "        tickmode='array'\n",
    "    )\n",
    "    \n",
    "    for _, row in df_viz_tmp[df_viz_tmp['model'].str.contains('Qwen')].sort_values('adherent_and_correct', ascending=False).drop_duplicates(subset=['model', 'encoding_scheme'], keep='first').iterrows():\n",
    "        if row['encoding_scheme'] == 'identity' and ('7B' in row['model'] or '14B' in row['model']):\n",
    "            print(row['adherent_and_correct'], row['model'])\n",
    "            fig.add_hline(y=row['adherent_and_correct'], annotation_text=row['model'].split('2.5-')[1] + \" unciphered\", line_dash='dot', line=dict(color='rgba(0, 0, 0, 0.3)'), annotation_position=\"top left\", annotation_font_color='#878787',)\n",
    "        elif row['encoding_scheme'] == 'zero_shot'  and ('14B' in row['model']):\n",
    "            fig.add_hline(y=row['adherent_and_correct'], annotation_text=row['model'].split('2.5-')[1] + \" direct answering\", line_dash='dot', line=dict(color='rgba(0, 0, 0, 0.3)'), annotation_position=\"top left\", annotation_font_color='#878787',)\n",
    "    \n",
    "    plotly.io.write_image(fig, f'paper/scaling_laws/datascaling_math_score_{encoding_scheme}.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021bf96-51f9-4a7b-bf3d-3b51d976a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for encoding_scheme in ['dot_between_chars', 'zero_shot', 'identity']:\n",
    "\n",
    "    \n",
    "    fig = px.line(df_viz_tmp[(df_viz_tmp['encoding_scheme'] == encoding_scheme) & (df_viz_tmp['model'].str.contains('Qwen'))],\n",
    "                  x='num_training_tokens', y='backtranslation_bleu_scores', color='model', markers=True, log_x=True, color_discrete_map=d_qwen_gradient)\n",
    "    \n",
    "    fig.update_layout(height=400, width=525, template=\"plotly_white\", font=dict(size=15), showlegend=False)\n",
    "    fig.update_yaxes(title=\"BLEU score\")\n",
    "    fig.update_xaxes(title=\"# fine-tuning tokens\")\n",
    "    \n",
    "    df_for_labels = df_viz_tmp[(df_viz_tmp['encoding_scheme'] == encoding_scheme) & (df_viz_tmp['model'].str.contains('Qwen'))]\n",
    "    if encoding_scheme != 'identity':\n",
    "        for model in df_for_labels['model'].unique():\n",
    "            model_data = df_for_labels[df_for_labels['model'] == model]\n",
    "            # Get the point with maximum x value (rightmost point)\n",
    "            max_x_row = model_data.loc[model_data['num_training_tokens'].idxmin()]\n",
    "            \n",
    "            fig.add_annotation(\n",
    "                x=np.log10(max_x_row['num_training_tokens']),\n",
    "                y=max_x_row['backtranslation_bleu_scores'],\n",
    "                text=model.split('2.5-')[1] if '2.5-' in model else model,\n",
    "                showarrow=False,\n",
    "                xanchor='right',\n",
    "                yanchor='middle',\n",
    "                xshift=-10,\n",
    "                font=dict(size=16, color=d_qwen_gradient.get(model, 'black')),\n",
    "            )\n",
    "    \n",
    "    \n",
    "    def format_tokens(value):\n",
    "        if value >= 1_000_000_000:\n",
    "            return f'{value/1_000_000_000:.0f}B' if value % 1_000_000_000 == 0 else f'{value/1_000_000_000:.1f}B'\n",
    "        elif value >= 1_000_000:\n",
    "            return f'{value/1_000_000:.0f}M' if value % 1_000_000 == 0 else f'{value/1_000_000:.1f}M'\n",
    "        else:\n",
    "            return str(value)\n",
    "    \n",
    "    # Generate tickvals based on your data range\n",
    "    tickvals = [100_000_000, 200_000_000, 500_000_000, 1_000_000_000, 2_000_000_000, 5_000_000_000]\n",
    "    ticktext = [format_tokens(val) for val in tickvals]\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        title=\"# fine-tuning tokens\",\n",
    "        tickvals=tickvals,\n",
    "        ticktext=ticktext,\n",
    "        tickmode='array'\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(range=[80, 100])\n",
    "\n",
    "    plotly.io.write_image(fig, f'paper/scaling_laws/datascaling_translation_bleu_{encoding_scheme}.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f49096-6779-436f-b773-e6a379c64f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
